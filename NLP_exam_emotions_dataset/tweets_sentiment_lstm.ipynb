{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>NLP Course <br><small>Graded Project Instructions <br>Spring 2023</small></center>\n",
    "\n",
    "About the dataset: \n",
    "\n",
    "List of tweet texts with emotion labels like joy, sadness, fear, anger... \n",
    "Dataset is split into train, test and validation sets for building the machine learning model. At first, you are \n",
    "given only train and test sets. The validation one will be given in the end of the project for you to check \n",
    "the final performance of your algorithm (to make sure there is no overfitting over the test data). \n",
    "You can work on this project on group of one, two or three students. This exercise is mandatory, not \n",
    "giving it back is equivalent to getting to lowest grade. \n",
    "Goal: \n",
    "\n",
    "• Train different kind of models able to classify each text according to the sentiment mainly present \n",
    "in it \n",
    "\n",
    "• Compare the results of your different models and try to analyze and explain the differences\n",
    "\n",
    "Train different classification models relying mainly on \n",
    "\n",
    "1. A Fully Connected Neural Network (see Course 2) 5 points \n",
    "\n",
    "2. A Recurrent Neural Network, based on LSTM or GRU (see Course 3) 5 points \n",
    "\n",
    "3. A fine-tuned Transformer Architecture from a pretrained model that can be found on sites \n",
    "like HuggingFace (see Course 4) 5 points \n",
    "\n",
    "4. Compare the different models to find the best approach and try to duplicate it on a “real life” \n",
    "text classification approach (this new “real life” dataset will be given to you soon) 5 points"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and Preprocessing the data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet sentiment\n",
       "0                            i didnt feel humiliated   sadness\n",
       "1  i can go from feeling so hopeless to so damned...   sadness\n",
       "2   im grabbing a minute to post i feel greedy wrong     anger\n",
       "3  i am ever feeling nostalgic about the fireplac...      love\n",
       "4                               i am feeling grouchy     anger"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('./train.txt', header=None, delimiter=';')\n",
    "df_test = pd.read_csv('./test.txt', header=None, delimiter=';')\n",
    "df_train = df_train.rename(columns={0: 'tweet', 1: 'sentiment'})\n",
    "df_test = df_test.rename(columns={0: 'tweet', 1: 'sentiment'})\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(joy         5362\n",
       " sadness     4666\n",
       " anger       2159\n",
       " fear        1937\n",
       " love        1304\n",
       " surprise     572\n",
       " Name: sentiment, dtype: int64,\n",
       " (16000, 2))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['sentiment'].value_counts(), df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(joy         695\n",
       " sadness     581\n",
       " anger       275\n",
       " fear        224\n",
       " love        159\n",
       " surprise     66\n",
       " Name: sentiment, dtype: int64,\n",
       " (2000, 2))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['sentiment'].value_counts(), df_test.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN, LSTM and GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(history):\n",
    "    hist_df = pd.DataFrame(history.history)\n",
    "    hist_df.columns=[\"loss\", \"accuracy\", \"val_loss\", \"val_accuracy\"]\n",
    "    hist_df.index = np.arange(1, len(hist_df)+1)\n",
    "\n",
    "    fig, axs = plt.subplots(nrows=2, sharex=True, figsize=(16, 10))\n",
    "    axs[0].plot(hist_df.val_accuracy, lw=3, label='Validation Accuracy')\n",
    "    axs[0].plot(hist_df.accuracy, lw=3, label='Training Accuracy')\n",
    "    axs[0].set_ylabel('Accuracy')\n",
    "    axs[0].set_xlabel('Epoch')\n",
    "    axs[0].grid()\n",
    "    axs[0].legend(loc=0)\n",
    "    axs[1].plot(hist_df.val_loss, lw=3, label='Validation Loss')\n",
    "    axs[1].plot(hist_df.loss, lw=3, label='Training Loss')\n",
    "    axs[1].set_ylabel('Loss')\n",
    "    axs[1].set_xlabel('Epoch')\n",
    "    axs[1].grid()\n",
    "    axs[1].legend(loc=0)\n",
    "\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet sentiment\n",
       "0                            i didnt feel humiliated   sadness\n",
       "1  i can go from feeling so hopeless to so damned...   sadness\n",
       "2   im grabbing a minute to post i feel greedy wrong     anger\n",
       "3  i am ever feeling nostalgic about the fireplac...      love\n",
       "4                               i am feeling grouchy     anger"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.metrics import Precision, Recall, AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_length = df_train['tweet'].map(lambda x: len(x)).sort_values().values[-1] # the length of the longest tweet 300\n",
    "max_length = 100\n",
    "trunc_type='post'\n",
    "# oov_tok = \"<OOV>\"\n",
    "\n",
    "tokenizer = Tokenizer() #(num_words = vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(df_train['tweet'])\n",
    "word_index = tokenizer.word_index\n",
    "sequences = tokenizer.texts_to_sequences(df_train['tweet'])\n",
    "padded = pad_sequences(sequences, maxlen=max_length, truncating=trunc_type)\n",
    "\n",
    "testing_sequences = tokenizer.texts_to_sequences(df_test['tweet'])\n",
    "testing_padded = pad_sequences(testing_sequences,maxlen=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(df_train['sentiment'])\n",
    "y_test = le.transform(df_test['sentiment'])\n",
    "y_train_encoded = to_categorical(y_train)\n",
    "y_test_encoded = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_8 (Embedding)     (None, 100, 100)          1521300   \n",
      "                                                                 \n",
      " bidirectional_8 (Bidirectio  (None, 128)              84480     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 32)                4128      \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 6)                 198       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,610,106\n",
      "Trainable params: 1,610,106\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "embedding_dim = max_length\n",
    "\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    Bidirectional(LSTM(64)), #32 \n",
    "    Dropout(0.4),\n",
    "    Dense(32, activation='leaky_relu', kernel_regularizer='l1_l2'),\n",
    "    Dropout(0.4),\n",
    "    Dense(6, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "loss_function = 'categorical_crossentropy'\n",
    "optimizer = 'adam'\n",
    "\n",
    "model.compile(loss=loss_function, optimizer=optimizer, metrics=['accuracy', Precision(), Recall(), AUC()])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "400/400 [==============================] - 30s 67ms/step - loss: 2.4233 - accuracy: 0.3245 - precision: 0.4309 - recall: 0.0041 - auc: 0.7091 - val_loss: 1.5493 - val_accuracy: 0.3656 - val_precision: 0.9252 - val_recall: 0.0309 - val_auc: 0.7762\n",
      "Epoch 2/50\n",
      "400/400 [==============================] - 26s 64ms/step - loss: 1.3558 - accuracy: 0.5248 - precision: 0.8238 - recall: 0.2881 - auc: 0.8427 - val_loss: 1.1211 - val_accuracy: 0.6481 - val_precision: 0.8610 - val_recall: 0.5344 - val_auc: 0.9052\n",
      "Epoch 3/50\n",
      "400/400 [==============================] - 27s 69ms/step - loss: 1.0572 - accuracy: 0.6716 - precision: 0.8896 - recall: 0.5251 - auc: 0.9162 - val_loss: 1.0921 - val_accuracy: 0.6612 - val_precision: 0.8702 - val_recall: 0.4984 - val_auc: 0.9091\n",
      "Epoch 4/50\n",
      "400/400 [==============================] - 28s 69ms/step - loss: 0.8960 - accuracy: 0.7040 - precision: 0.9373 - recall: 0.5618 - auc: 0.9419 - val_loss: 0.9403 - val_accuracy: 0.6894 - val_precision: 0.9031 - val_recall: 0.5478 - val_auc: 0.9358\n",
      "Epoch 5/50\n",
      "400/400 [==============================] - 28s 70ms/step - loss: 0.7791 - accuracy: 0.7340 - precision: 0.9675 - recall: 0.5907 - auc: 0.9585 - val_loss: 0.7929 - val_accuracy: 0.7309 - val_precision: 0.9485 - val_recall: 0.5587 - val_auc: 0.9565\n",
      "Epoch 6/50\n",
      "400/400 [==============================] - 29s 71ms/step - loss: 0.6859 - accuracy: 0.7770 - precision: 0.9624 - recall: 0.6138 - auc: 0.9710 - val_loss: 0.7417 - val_accuracy: 0.7672 - val_precision: 0.9258 - val_recall: 0.6081 - val_auc: 0.9630\n",
      "Epoch 7/50\n",
      "400/400 [==============================] - 29s 73ms/step - loss: 0.5951 - accuracy: 0.8013 - precision: 0.9493 - recall: 0.6690 - auc: 0.9796 - val_loss: 0.6215 - val_accuracy: 0.7812 - val_precision: 0.9301 - val_recall: 0.6488 - val_auc: 0.9742\n",
      "Epoch 8/50\n",
      "400/400 [==============================] - 27s 68ms/step - loss: 0.5313 - accuracy: 0.8220 - precision: 0.9337 - recall: 0.7014 - auc: 0.9838 - val_loss: 0.6059 - val_accuracy: 0.7928 - val_precision: 0.9221 - val_recall: 0.6625 - val_auc: 0.9768\n",
      "Epoch 9/50\n",
      "400/400 [==============================] - 27s 67ms/step - loss: 0.5055 - accuracy: 0.8292 - precision: 0.9153 - recall: 0.7372 - auc: 0.9858 - val_loss: 0.6336 - val_accuracy: 0.7975 - val_precision: 0.8463 - val_recall: 0.7316 - val_auc: 0.9746\n",
      "Epoch 10/50\n",
      "400/400 [==============================] - 27s 68ms/step - loss: 0.4722 - accuracy: 0.8397 - precision: 0.9075 - recall: 0.7630 - auc: 0.9876 - val_loss: 0.5836 - val_accuracy: 0.8097 - val_precision: 0.8345 - val_recall: 0.7831 - val_auc: 0.9762\n",
      "Epoch 11/50\n",
      "400/400 [==============================] - 28s 69ms/step - loss: 0.4340 - accuracy: 0.8543 - precision: 0.9071 - recall: 0.7862 - auc: 0.9892 - val_loss: 0.5505 - val_accuracy: 0.8138 - val_precision: 0.8305 - val_recall: 0.7903 - val_auc: 0.9791\n",
      "Epoch 12/50\n",
      "400/400 [==============================] - 27s 67ms/step - loss: 0.4227 - accuracy: 0.8592 - precision: 0.9047 - recall: 0.7991 - auc: 0.9901 - val_loss: 0.5830 - val_accuracy: 0.8144 - val_precision: 0.8554 - val_recall: 0.7669 - val_auc: 0.9776\n",
      "Epoch 13/50\n",
      "400/400 [==============================] - 27s 67ms/step - loss: 0.3891 - accuracy: 0.8929 - precision: 0.9256 - recall: 0.8485 - auc: 0.9931 - val_loss: 0.5310 - val_accuracy: 0.9009 - val_precision: 0.9188 - val_recall: 0.8881 - val_auc: 0.9818\n",
      "Epoch 14/50\n",
      "400/400 [==============================] - 29s 74ms/step - loss: 0.3363 - accuracy: 0.9474 - precision: 0.9593 - recall: 0.9315 - auc: 0.9962 - val_loss: 0.4662 - val_accuracy: 0.9166 - val_precision: 0.9231 - val_recall: 0.9122 - val_auc: 0.9846\n",
      "Epoch 15/50\n",
      "400/400 [==============================] - 29s 73ms/step - loss: 0.2916 - accuracy: 0.9610 - precision: 0.9689 - recall: 0.9526 - auc: 0.9974 - val_loss: 0.4660 - val_accuracy: 0.9106 - val_precision: 0.9190 - val_recall: 0.9047 - val_auc: 0.9836\n",
      "Epoch 16/50\n",
      "400/400 [==============================] - 28s 70ms/step - loss: 0.2748 - accuracy: 0.9663 - precision: 0.9724 - recall: 0.9569 - auc: 0.9975 - val_loss: 0.4610 - val_accuracy: 0.9103 - val_precision: 0.9179 - val_recall: 0.9044 - val_auc: 0.9842\n",
      "Epoch 17/50\n",
      "400/400 [==============================] - 28s 71ms/step - loss: 0.2561 - accuracy: 0.9682 - precision: 0.9742 - recall: 0.9606 - auc: 0.9979 - val_loss: 0.4332 - val_accuracy: 0.9184 - val_precision: 0.9278 - val_recall: 0.9116 - val_auc: 0.9857\n",
      "Epoch 18/50\n",
      "400/400 [==============================] - 28s 70ms/step - loss: 0.2221 - accuracy: 0.9762 - precision: 0.9806 - recall: 0.9700 - auc: 0.9990 - val_loss: 0.4163 - val_accuracy: 0.9216 - val_precision: 0.9299 - val_recall: 0.9156 - val_auc: 0.9855\n",
      "Epoch 19/50\n",
      "400/400 [==============================] - 27s 67ms/step - loss: 0.2484 - accuracy: 0.9716 - precision: 0.9778 - recall: 0.9646 - auc: 0.9981 - val_loss: 0.4546 - val_accuracy: 0.9178 - val_precision: 0.9247 - val_recall: 0.9134 - val_auc: 0.9835\n",
      "Epoch 20/50\n",
      "400/400 [==============================] - 25s 63ms/step - loss: 0.2289 - accuracy: 0.9761 - precision: 0.9809 - recall: 0.9698 - auc: 0.9981 - val_loss: 0.4607 - val_accuracy: 0.9141 - val_precision: 0.9251 - val_recall: 0.9103 - val_auc: 0.9825\n",
      "Epoch 21/50\n",
      "400/400 [==============================] - 29s 72ms/step - loss: 0.2009 - accuracy: 0.9800 - precision: 0.9848 - recall: 0.9755 - auc: 0.9989 - val_loss: 0.4653 - val_accuracy: 0.9156 - val_precision: 0.9241 - val_recall: 0.9091 - val_auc: 0.9838\n"
     ]
    }
   ],
   "source": [
    "predictors = np.array(padded) \n",
    "label = np.array(y_train_encoded)\n",
    "epochs_value = 50\n",
    "validation_split_value = 0.2\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=3)\n",
    "\n",
    "history = model.fit(predictors, label, epochs=epochs_value, verbose=1, validation_split=validation_split_value, callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "plot_results(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 5s 54ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.91      0.90       275\n",
      "           1       0.85      0.92      0.88       224\n",
      "           2       0.95      0.92      0.94       695\n",
      "           3       0.86      0.77      0.81       159\n",
      "           4       0.94      0.97      0.95       581\n",
      "           5       0.81      0.73      0.77        66\n",
      "\n",
      "    accuracy                           0.92      2000\n",
      "   macro avg       0.88      0.87      0.88      2000\n",
      "weighted avg       0.91      0.92      0.91      2000\n",
      "\n",
      "[[249  12   2   0  12   0]\n",
      " [  8 206   1   0   4   5]\n",
      " [  7   6 642  19  16   5]\n",
      " [  4   0  27 123   4   1]\n",
      " [ 11   4   4   0 562   0]\n",
      " [  1  14   2   1   0  48]]\n",
      "0.915\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "predictions = model.predict(testing_padded)\n",
    "prediction_labels = predictions.argmax(axis=1)\n",
    "print(classification_report(y_test, prediction_labels))\n",
    "print(confusion_matrix(y_test, prediction_labels))\n",
    "print(accuracy_score(y_test, prediction_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
