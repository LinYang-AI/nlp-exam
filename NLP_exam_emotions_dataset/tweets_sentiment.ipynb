{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>NLP Course <br><small>Graded Project Instructions <br>Spring 2023</small></center>\n",
    "\n",
    "About the dataset: \n",
    "\n",
    "List of tweet texts with emotion labels like joy, sadness, fear, anger... \n",
    "Dataset is split into train, test and validation sets for building the machine learning model. At first, you are \n",
    "given only train and test sets. The validation one will be given in the end of the project for you to check \n",
    "the final performance of your algorithm (to make sure there is no overfitting over the test data). \n",
    "You can work on this project on group of one, two or three students. This exercise is mandatory, not \n",
    "giving it back is equivalent to getting to lowest grade. \n",
    "Goal: \n",
    "\n",
    "• Train different kind of models able to classify each text according to the sentiment mainly present \n",
    "in it \n",
    "\n",
    "• Compare the results of your different models and try to analyze and explain the differences\n",
    "\n",
    "Train different classification models relying mainly on \n",
    "\n",
    "1. A Fully Connected Neural Network (see Course 2) 5 points \n",
    "\n",
    "2. A Recurrent Neural Network, based on LSTM or GRU (see Course 3) 5 points \n",
    "\n",
    "3. A fine-tuned Transformer Architecture from a pretrained model that can be found on sites \n",
    "like HuggingFace (see Course 4) 5 points \n",
    "\n",
    "4. Compare the different models to find the best approach and try to duplicate it on a “real life” \n",
    "text classification approach (this new “real life” dataset will be given to you soon) 5 points"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and Preprocessing the data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet sentiment\n",
       "0                            i didnt feel humiliated   sadness\n",
       "1  i can go from feeling so hopeless to so damned...   sadness\n",
       "2   im grabbing a minute to post i feel greedy wrong     anger\n",
       "3  i am ever feeling nostalgic about the fireplac...      love\n",
       "4                               i am feeling grouchy     anger"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('./train.txt', header=None, delimiter=';')\n",
    "df_test = pd.read_csv('./test.txt', header=None, delimiter=';')\n",
    "df_train = df_train.rename(columns={0: 'tweet', 1: 'sentiment'})\n",
    "df_test = df_test.rename(columns={0: 'tweet', 1: 'sentiment'})\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(joy         5362\n",
       " sadness     4666\n",
       " anger       2159\n",
       " fear        1937\n",
       " love        1304\n",
       " surprise     572\n",
       " Name: sentiment, dtype: int64,\n",
       " (16000, 2))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['sentiment'].value_counts(), df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(joy         695\n",
       " sadness     581\n",
       " anger       275\n",
       " fear        224\n",
       " love        159\n",
       " surprise     66\n",
       " Name: sentiment, dtype: int64,\n",
       " (2000, 2))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['sentiment'].value_counts(), df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_train = df_train['tweet']\n",
    "texts_test = df_test['tweet']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization and Embedding"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet sentiment\n",
       "0                            i didnt feel humiliated   sadness\n",
       "1  i can go from feeling so hopeless to so damned...   sadness\n",
       "2   im grabbing a minute to post i feel greedy wrong     anger\n",
       "3  i am ever feeling nostalgic about the fireplac...      love\n",
       "4                               i am feeling grouchy     anger"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "def preprocess_text(text):\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.lemma_.lower().strip() for token in doc if not token.is_stop and not token.is_punct]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "      <td>not feel humiliate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>feel hopeless damn hopeful care awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>anger</td>\n",
       "      <td>m grab minute post feel greedy wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>love</td>\n",
       "      <td>feel nostalgic fireplace know property</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>anger</td>\n",
       "      <td>feel grouchy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet sentiment  \\\n",
       "0                            i didnt feel humiliated   sadness   \n",
       "1  i can go from feeling so hopeless to so damned...   sadness   \n",
       "2   im grabbing a minute to post i feel greedy wrong     anger   \n",
       "3  i am ever feeling nostalgic about the fireplac...      love   \n",
       "4                               i am feeling grouchy     anger   \n",
       "\n",
       "                                processed  \n",
       "0                      not feel humiliate  \n",
       "1   feel hopeless damn hopeful care awake  \n",
       "2    m grab minute post feel greedy wrong  \n",
       "3  feel nostalgic fireplace know property  \n",
       "4                            feel grouchy  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['processed'] = df_train['tweet'].apply(preprocess_text)\n",
    "df_test['processed'] = df_test['tweet'].apply(preprocess_text)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation, NMF\n",
    "\n",
    "tfidf = TfidfVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
    "\n",
    "dtm_train = tfidf.fit_transform(df_train['processed'])\n",
    "dtm_test = tfidf.transform(df_test['processed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LatentDirichletAllocation(learning_method=&#x27;online&#x27;, learning_offset=50.0,\n",
       "                          max_iter=5, n_components=32, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LatentDirichletAllocation</label><div class=\"sk-toggleable__content\"><pre>LatentDirichletAllocation(learning_method=&#x27;online&#x27;, learning_offset=50.0,\n",
       "                          max_iter=5, n_components=32, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LatentDirichletAllocation(learning_method='online', learning_offset=50.0,\n",
       "                          max_iter=5, n_components=32, random_state=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "lda = LatentDirichletAllocation(n_components=32, max_iter=5, learning_method='online', learning_offset=50.,random_state=0)\n",
    "lda.fit(dtm_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000, 32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_train = lda.transform(dtm_train)\n",
    "lda_test = lda.transform(dtm_test)\n",
    "lda_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01465309, 0.01465309, 0.01465309, ..., 0.01465309, 0.01465309,\n",
       "        0.01465309],\n",
       "       [0.15621728, 0.00949822, 0.00949822, ..., 0.00949822, 0.00949822,\n",
       "        0.00949822],\n",
       "       [0.00951083, 0.00951083, 0.00951083, ..., 0.00951083, 0.14678471,\n",
       "        0.00951083],\n",
       "       ...,\n",
       "       [0.01122012, 0.01122012, 0.01122012, ..., 0.01122012, 0.01122012,\n",
       "        0.01122012],\n",
       "       [0.0103985 , 0.0103985 , 0.0103985 , ..., 0.0103985 , 0.0103985 ,\n",
       "        0.0103985 ],\n",
       "       [0.01042829, 0.01042829, 0.01042829, ..., 0.01042829, 0.01042829,\n",
       "        0.01042829]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4, 0, ..., 2, 0, 4])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(df_train['sentiment'])\n",
    "y_test = le.transform(df_test['sentiment'])\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18000, 5587)\n",
      "(11520, 5587)\n",
      "(2880, 5587)\n",
      "(3600, 5587)\n",
      "(11520,)\n",
      "(2880,)\n",
      "(3600,)\n"
     ]
    }
   ],
   "source": [
    "X_train_ = dtm_train.toarray()\n",
    "X_test_ = dtm_test.toarray()\n",
    "X_train_ = np.vstack((X_train_, X_test_))\n",
    "y_train_ = np.concatenate((y_train, y_test))\n",
    "\n",
    "print(X_train_.shape)\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train_), y=y_train_)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_, X_test_, y_train_, y_test_ = train_test_split(X_train_, y_train_, test_size=0.2, random_state=42, stratify=y_train_)\n",
    "X_train_, X_val_, y_train_, y_val_ = train_test_split(X_train_, y_train_, test_size=0.2, random_state=42, stratify=y_train_)\n",
    "\n",
    "print(X_train_.shape)\n",
    "print(X_val_.shape)\n",
    "print(X_test_.shape)\n",
    "print(y_train_.shape)\n",
    "print(y_val_.shape)\n",
    "print(y_test_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11520, 6), (3600, 6), (2880, 6))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "y_train_encoded = to_categorical(y_train_)\n",
    "y_test_encoded = to_categorical(y_test_)\n",
    "y_val_encoded = to_categorical(y_val_)\n",
    "y_train_encoded.shape, y_test_encoded.shape, y_val_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# experiments with standardized data is not as good as without standardization\n",
    "# std = StandardScaler()\n",
    "# std.fit(X_train_)\n",
    "# X_train_std = std.transform(X_train_)\n",
    "# X_test_std = std.transform(X_test_)\n",
    "# X_val_std = std.transform(X_val_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Experiements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweets_sentiment(df_train):\n",
    "    i = 0\n",
    "    dict_label = []\n",
    "    list_embed = []    \n",
    "    size_data = df_train.shape[0]\n",
    "\n",
    "    for sentence in list(df_train.itertuples())[0:size_data]:\n",
    "        text_embed =np.ndarray.flatten(nlp(sentence.tweet).vector)\n",
    "        observed_sentiment = sentence.sentiment\n",
    "        if observed_sentiment == 'joy':\n",
    "            label = 0.0\n",
    "        elif observed_sentiment == 'sadness':\n",
    "            label = 1.0\n",
    "        elif observed_sentiment == 'anger':\n",
    "            label = 2.0\n",
    "        elif observed_sentiment == 'fear':\n",
    "            label = 3.0\n",
    "        elif observed_sentiment == 'love':\n",
    "            label = 4.0\n",
    "        else:\n",
    "            label = 5.0\n",
    "        dict_label.append(label)\n",
    "        list_embed.append(np.array([text_embed]))\n",
    "        i += 1\n",
    "    return dict_label, list_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = get_tweets_sentiment(df_train)\n",
    "test_set = get_tweets_sentiment(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_label = training_set[0]\n",
    "X_train_embed = np.array(training_set[1])\n",
    "\n",
    "y_test_label = test_set[0]\n",
    "X_test_embed = np.array(test_set[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame.from_dict(X_train_embed_dict, orient='index')\n",
    "X_test = pd.DataFrame.from_dict(X_test_embed_dict, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.DataFrame({'sentiment': pd.Series(y_train_label)})\n",
    "y_test = pd.DataFrame({'sentiment': pd.Series(y_test_label)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.join(y_train)\n",
    "X_test = X_test.join(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.244544</td>\n",
       "      <td>3.320704</td>\n",
       "      <td>-4.349200</td>\n",
       "      <td>-4.938100</td>\n",
       "      <td>-5.548332</td>\n",
       "      <td>-0.334612</td>\n",
       "      <td>2.851000</td>\n",
       "      <td>4.615040</td>\n",
       "      <td>-3.909860</td>\n",
       "      <td>1.156213</td>\n",
       "      <td>...</td>\n",
       "      <td>1.858890</td>\n",
       "      <td>3.743104</td>\n",
       "      <td>-4.620500</td>\n",
       "      <td>-2.027022</td>\n",
       "      <td>-0.458748</td>\n",
       "      <td>2.146400</td>\n",
       "      <td>0.473382</td>\n",
       "      <td>-5.862100</td>\n",
       "      <td>3.241746</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.223656</td>\n",
       "      <td>1.766241</td>\n",
       "      <td>-4.094052</td>\n",
       "      <td>-2.746358</td>\n",
       "      <td>-0.272167</td>\n",
       "      <td>1.918542</td>\n",
       "      <td>0.606388</td>\n",
       "      <td>3.744067</td>\n",
       "      <td>-2.564810</td>\n",
       "      <td>0.448512</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.478352</td>\n",
       "      <td>1.169669</td>\n",
       "      <td>-1.649001</td>\n",
       "      <td>-0.494671</td>\n",
       "      <td>0.486054</td>\n",
       "      <td>0.268000</td>\n",
       "      <td>0.201243</td>\n",
       "      <td>-4.229311</td>\n",
       "      <td>2.885545</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.559911</td>\n",
       "      <td>1.445776</td>\n",
       "      <td>-3.058882</td>\n",
       "      <td>-3.555917</td>\n",
       "      <td>-2.962154</td>\n",
       "      <td>-0.854085</td>\n",
       "      <td>1.796378</td>\n",
       "      <td>4.492185</td>\n",
       "      <td>-3.606849</td>\n",
       "      <td>1.852871</td>\n",
       "      <td>...</td>\n",
       "      <td>1.879795</td>\n",
       "      <td>2.678336</td>\n",
       "      <td>-0.826156</td>\n",
       "      <td>-1.163337</td>\n",
       "      <td>2.666765</td>\n",
       "      <td>2.665115</td>\n",
       "      <td>0.074175</td>\n",
       "      <td>-6.811033</td>\n",
       "      <td>4.418684</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.051930</td>\n",
       "      <td>1.353643</td>\n",
       "      <td>-2.263858</td>\n",
       "      <td>-2.285067</td>\n",
       "      <td>0.094969</td>\n",
       "      <td>0.224866</td>\n",
       "      <td>0.950704</td>\n",
       "      <td>5.104722</td>\n",
       "      <td>-2.586915</td>\n",
       "      <td>1.873142</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.487933</td>\n",
       "      <td>3.059388</td>\n",
       "      <td>-1.453429</td>\n",
       "      <td>-2.711442</td>\n",
       "      <td>0.441768</td>\n",
       "      <td>2.066405</td>\n",
       "      <td>-0.303266</td>\n",
       "      <td>-4.992957</td>\n",
       "      <td>2.634871</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.735625</td>\n",
       "      <td>-4.124410</td>\n",
       "      <td>-0.825107</td>\n",
       "      <td>-5.556050</td>\n",
       "      <td>-5.838550</td>\n",
       "      <td>-1.161450</td>\n",
       "      <td>-1.645423</td>\n",
       "      <td>4.546025</td>\n",
       "      <td>-5.097775</td>\n",
       "      <td>5.398050</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.893840</td>\n",
       "      <td>4.514425</td>\n",
       "      <td>-5.539950</td>\n",
       "      <td>-0.371385</td>\n",
       "      <td>0.628725</td>\n",
       "      <td>2.848050</td>\n",
       "      <td>0.691625</td>\n",
       "      <td>-6.790800</td>\n",
       "      <td>5.685215</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.244544  3.320704 -4.349200 -4.938100 -5.548332 -0.334612  2.851000   \n",
       "1  0.223656  1.766241 -4.094052 -2.746358 -0.272167  1.918542  0.606388   \n",
       "2 -0.559911  1.445776 -3.058882 -3.555917 -2.962154 -0.854085  1.796378   \n",
       "3  0.051930  1.353643 -2.263858 -2.285067  0.094969  0.224866  0.950704   \n",
       "4  1.735625 -4.124410 -0.825107 -5.556050 -5.838550 -1.161450 -1.645423   \n",
       "\n",
       "          7         8         9  ...       291       292       293       294  \\\n",
       "0  4.615040 -3.909860  1.156213  ...  1.858890  3.743104 -4.620500 -2.027022   \n",
       "1  3.744067 -2.564810  0.448512  ... -0.478352  1.169669 -1.649001 -0.494671   \n",
       "2  4.492185 -3.606849  1.852871  ...  1.879795  2.678336 -0.826156 -1.163337   \n",
       "3  5.104722 -2.586915  1.873142  ... -0.487933  3.059388 -1.453429 -2.711442   \n",
       "4  4.546025 -5.097775  5.398050  ... -0.893840  4.514425 -5.539950 -0.371385   \n",
       "\n",
       "        295       296       297       298       299  sentiment  \n",
       "0 -0.458748  2.146400  0.473382 -5.862100  3.241746        1.0  \n",
       "1  0.486054  0.268000  0.201243 -4.229311  2.885545        1.0  \n",
       "2  2.666765  2.665115  0.074175 -6.811033  4.418684        2.0  \n",
       "3  0.441768  2.066405 -0.303266 -4.992957  2.634871        4.0  \n",
       "4  0.628725  2.848050  0.691625 -6.790800  5.685215        2.0  \n",
       "\n",
       "[5 rows x 301 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.646664</td>\n",
       "      <td>-0.060523</td>\n",
       "      <td>-3.147135</td>\n",
       "      <td>-3.579636</td>\n",
       "      <td>-3.076929</td>\n",
       "      <td>0.218848</td>\n",
       "      <td>1.519892</td>\n",
       "      <td>5.144284</td>\n",
       "      <td>-3.581683</td>\n",
       "      <td>1.069953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.593741</td>\n",
       "      <td>2.277497</td>\n",
       "      <td>-2.253524</td>\n",
       "      <td>-1.521812</td>\n",
       "      <td>3.472223</td>\n",
       "      <td>2.587848</td>\n",
       "      <td>-0.401808</td>\n",
       "      <td>-4.964146</td>\n",
       "      <td>6.498646</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.025809</td>\n",
       "      <td>-1.956960</td>\n",
       "      <td>-2.446465</td>\n",
       "      <td>-5.423300</td>\n",
       "      <td>-3.885370</td>\n",
       "      <td>-1.520104</td>\n",
       "      <td>1.121217</td>\n",
       "      <td>5.694414</td>\n",
       "      <td>-4.900402</td>\n",
       "      <td>3.754002</td>\n",
       "      <td>...</td>\n",
       "      <td>1.422118</td>\n",
       "      <td>3.222383</td>\n",
       "      <td>-2.574567</td>\n",
       "      <td>-1.702118</td>\n",
       "      <td>2.256141</td>\n",
       "      <td>1.779407</td>\n",
       "      <td>-1.356126</td>\n",
       "      <td>-8.708911</td>\n",
       "      <td>2.917247</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.379754</td>\n",
       "      <td>2.021777</td>\n",
       "      <td>-4.115047</td>\n",
       "      <td>-3.925060</td>\n",
       "      <td>-1.801270</td>\n",
       "      <td>-0.509126</td>\n",
       "      <td>0.535020</td>\n",
       "      <td>5.488764</td>\n",
       "      <td>-2.835824</td>\n",
       "      <td>2.021240</td>\n",
       "      <td>...</td>\n",
       "      <td>0.886601</td>\n",
       "      <td>1.461787</td>\n",
       "      <td>-3.441629</td>\n",
       "      <td>-0.755121</td>\n",
       "      <td>0.246921</td>\n",
       "      <td>1.282389</td>\n",
       "      <td>0.437262</td>\n",
       "      <td>-7.624653</td>\n",
       "      <td>1.427426</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.127041</td>\n",
       "      <td>-0.113063</td>\n",
       "      <td>-3.459354</td>\n",
       "      <td>-0.322099</td>\n",
       "      <td>1.723492</td>\n",
       "      <td>-1.035290</td>\n",
       "      <td>-0.076402</td>\n",
       "      <td>4.944045</td>\n",
       "      <td>-1.521673</td>\n",
       "      <td>2.070339</td>\n",
       "      <td>...</td>\n",
       "      <td>0.572273</td>\n",
       "      <td>1.472116</td>\n",
       "      <td>-2.730601</td>\n",
       "      <td>-0.811309</td>\n",
       "      <td>1.271370</td>\n",
       "      <td>0.422168</td>\n",
       "      <td>-0.468638</td>\n",
       "      <td>-6.789992</td>\n",
       "      <td>-0.746808</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.536985</td>\n",
       "      <td>2.090232</td>\n",
       "      <td>-2.700058</td>\n",
       "      <td>-3.622260</td>\n",
       "      <td>-0.668053</td>\n",
       "      <td>-1.547755</td>\n",
       "      <td>1.065863</td>\n",
       "      <td>4.673425</td>\n",
       "      <td>-2.375048</td>\n",
       "      <td>2.303454</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.101827</td>\n",
       "      <td>3.305504</td>\n",
       "      <td>-0.958210</td>\n",
       "      <td>-1.648267</td>\n",
       "      <td>2.466753</td>\n",
       "      <td>2.094077</td>\n",
       "      <td>0.081915</td>\n",
       "      <td>-5.603895</td>\n",
       "      <td>2.635907</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.646664 -0.060523 -3.147135 -3.579636 -3.076929  0.218848  1.519892   \n",
       "1  2.025809 -1.956960 -2.446465 -5.423300 -3.885370 -1.520104  1.121217   \n",
       "2 -0.379754  2.021777 -4.115047 -3.925060 -1.801270 -0.509126  0.535020   \n",
       "3 -2.127041 -0.113063 -3.459354 -0.322099  1.723492 -1.035290 -0.076402   \n",
       "4 -1.536985  2.090232 -2.700058 -3.622260 -0.668053 -1.547755  1.065863   \n",
       "\n",
       "          7         8         9  ...       291       292       293       294  \\\n",
       "0  5.144284 -3.581683  1.069953  ...  0.593741  2.277497 -2.253524 -1.521812   \n",
       "1  5.694414 -4.900402  3.754002  ...  1.422118  3.222383 -2.574567 -1.702118   \n",
       "2  5.488764 -2.835824  2.021240  ...  0.886601  1.461787 -3.441629 -0.755121   \n",
       "3  4.944045 -1.521673  2.070339  ...  0.572273  1.472116 -2.730601 -0.811309   \n",
       "4  4.673425 -2.375048  2.303454  ... -0.101827  3.305504 -0.958210 -1.648267   \n",
       "\n",
       "        295       296       297       298       299  sentiment  \n",
       "0  3.472223  2.587848 -0.401808 -4.964146  6.498646        1.0  \n",
       "1  2.256141  1.779407 -1.356126 -8.708911  2.917247        1.0  \n",
       "2  0.246921  1.282389  0.437262 -7.624653  1.427426        1.0  \n",
       "3  1.271370  0.422168 -0.468638 -6.789992 -0.746808        0.0  \n",
       "4  2.466753  2.094077  0.081915 -5.603895  2.635907        1.0  \n",
       "\n",
       "[5 rows x 301 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = X_train['sentiment']\n",
    "X_train = X_train.drop('sentiment', axis=1)\n",
    "\n",
    "y_test = X_test['sentiment']\n",
    "X_test = X_test.drop('sentiment', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16000, 6)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "y_train_encoded = to_categorical(y_train)\n",
    "y_test_encoded = to_categorical(y_test)\n",
    "print(y_train_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-11.600116729736328, 13.568775177001953)"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_num = np.inf\n",
    "max_num = -np.inf\n",
    "\n",
    "for i in range(300):\n",
    "    if min(X_train.iloc[:, i]) < min_num:\n",
    "        min_num = min(X_train.iloc[:, i])\n",
    "    if max(X_train.iloc[:, i]) > max_num:\n",
    "        max_num = max(X_train.iloc[:, i])\n",
    "min_num, max_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "std = StandardScaler()\n",
    "\n",
    "X_train = std.fit_transform(X_train)\n",
    "X_test = std.transform(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully connect NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 4096)              22888448  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2048)              8390656   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1024)              2098176   \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 512)               524800    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                32832     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 6)                 390       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,935,302\n",
      "Trainable params: 33,935,302\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras import Sequential\n",
    "import tensorflow as tf\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(4096, activation='selu', input_shape=(X_train_.shape[1],), kernel_regularizer=tf.keras.regularizers.l2(0.01)))\n",
    "model.add(Dense(2048, activation='selu', kernel_regularizer=tf.keras.regularizers.l2(0.01)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1024, activation='selu', kernel_regularizer=tf.keras.regularizers.l2(0.1)))\n",
    "# model.add(Dropout(0.2)) kernel_regularizer=tf.keras.regularizers.l2(0.01)\n",
    "model.add(Dense(512, activation='selu', ))\n",
    "model.add(Dropout(0.5))\n",
    "# model.add(Dense(128, activation='selu'))\n",
    "model.add(Dense(64, activation='selu',))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "\n",
    "model.layers[-1].bias.assign(class_weights)\n",
    "model.compile(optimizer='Adam', loss=tf.losses.categorical_crossentropy, metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.callbacks import EarlyStopping, CallbackList, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "def step_decay(epoch):\n",
    "    initial_lrate = 0.001\n",
    "    drop = 0.5\n",
    "    epochs_drop = 10.0\n",
    "    lrate = initial_lrate * math.pow(drop, math.floor((1 + epoch) / epochs_drop))\n",
    "    return lrate\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(step_decay)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', restore_best_weights=True, patience=5) # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-04 20:52:47.832212: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 7s 561ms/step - loss: 147.6198 - accuracy: 0.4026 - val_loss: 78.2411 - val_accuracy: 0.7299 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 6s 527ms/step - loss: 49.4107 - accuracy: 0.8329 - val_loss: 22.9675 - val_accuracy: 0.8309 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 8s 635ms/step - loss: 13.9102 - accuracy: 0.9003 - val_loss: 6.3203 - val_accuracy: 0.8510 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 7s 598ms/step - loss: 3.8598 - accuracy: 0.9103 - val_loss: 2.0725 - val_accuracy: 0.8438 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 8s 707ms/step - loss: 1.4440 - accuracy: 0.9042 - val_loss: 1.2961 - val_accuracy: 0.7976 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 9s 734ms/step - loss: 0.9928 - accuracy: 0.8970 - val_loss: 1.0691 - val_accuracy: 0.8306 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 8s 696ms/step - loss: 0.8557 - accuracy: 0.9029 - val_loss: 0.9641 - val_accuracy: 0.8319 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 8s 636ms/step - loss: 0.7524 - accuracy: 0.9155 - val_loss: 0.8923 - val_accuracy: 0.8337 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 7s 622ms/step - loss: 0.6849 - accuracy: 0.9187 - val_loss: 0.8967 - val_accuracy: 0.8319 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 9s 721ms/step - loss: 0.5908 - accuracy: 0.9450 - val_loss: 0.8441 - val_accuracy: 0.8340 - lr: 5.0000e-04\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 8s 683ms/step - loss: 0.5037 - accuracy: 0.9608 - val_loss: 0.7619 - val_accuracy: 0.8507 - lr: 5.0000e-04\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 8s 641ms/step - loss: 0.4532 - accuracy: 0.9690 - val_loss: 0.7412 - val_accuracy: 0.8472 - lr: 5.0000e-04\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 8s 661ms/step - loss: 0.4281 - accuracy: 0.9684 - val_loss: 0.7300 - val_accuracy: 0.8438 - lr: 5.0000e-04\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 8s 692ms/step - loss: 0.4193 - accuracy: 0.9691 - val_loss: 0.7325 - val_accuracy: 0.8389 - lr: 5.0000e-04\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 7s 620ms/step - loss: 0.4132 - accuracy: 0.9674 - val_loss: 0.7355 - val_accuracy: 0.8444 - lr: 5.0000e-04\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 9s 778ms/step - loss: 0.4006 - accuracy: 0.9701 - val_loss: 0.7134 - val_accuracy: 0.8403 - lr: 5.0000e-04\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 9s 731ms/step - loss: 0.3895 - accuracy: 0.9698 - val_loss: 0.7130 - val_accuracy: 0.8392 - lr: 5.0000e-04\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 8s 639ms/step - loss: 0.3824 - accuracy: 0.9700 - val_loss: 0.7263 - val_accuracy: 0.8462 - lr: 5.0000e-04\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 8s 695ms/step - loss: 0.3672 - accuracy: 0.9717 - val_loss: 0.7153 - val_accuracy: 0.8358 - lr: 5.0000e-04\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 9s 764ms/step - loss: 0.3422 - accuracy: 0.9802 - val_loss: 0.6974 - val_accuracy: 0.8403 - lr: 2.5000e-04\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 8s 677ms/step - loss: 0.3233 - accuracy: 0.9831 - val_loss: 0.6806 - val_accuracy: 0.8434 - lr: 2.5000e-04\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 8s 687ms/step - loss: 0.3114 - accuracy: 0.9834 - val_loss: 0.6761 - val_accuracy: 0.8389 - lr: 2.5000e-04\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 9s 714ms/step - loss: 0.3037 - accuracy: 0.9848 - val_loss: 0.6731 - val_accuracy: 0.8431 - lr: 2.5000e-04\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 8s 678ms/step - loss: 0.2996 - accuracy: 0.9852 - val_loss: 0.6843 - val_accuracy: 0.8424 - lr: 2.5000e-04\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 9s 711ms/step - loss: 0.3000 - accuracy: 0.9826 - val_loss: 0.6942 - val_accuracy: 0.8413 - lr: 2.5000e-04\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 8s 678ms/step - loss: 0.2980 - accuracy: 0.9827 - val_loss: 0.6775 - val_accuracy: 0.8410 - lr: 2.5000e-04\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 9s 759ms/step - loss: 0.2883 - accuracy: 0.9857 - val_loss: 0.6816 - val_accuracy: 0.8392 - lr: 2.5000e-04\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 8s 641ms/step - loss: 0.2845 - accuracy: 0.9861 - val_loss: 0.6684 - val_accuracy: 0.8417 - lr: 2.5000e-04\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 9s 728ms/step - loss: 0.2795 - accuracy: 0.9859 - val_loss: 0.6649 - val_accuracy: 0.8406 - lr: 2.5000e-04\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 9s 780ms/step - loss: 0.2708 - accuracy: 0.9871 - val_loss: 0.6656 - val_accuracy: 0.8424 - lr: 1.2500e-04\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 9s 728ms/step - loss: 0.2661 - accuracy: 0.9885 - val_loss: 0.6619 - val_accuracy: 0.8403 - lr: 1.2500e-04\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 10s 816ms/step - loss: 0.2663 - accuracy: 0.9871 - val_loss: 0.6656 - val_accuracy: 0.8389 - lr: 1.2500e-04\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 9s 749ms/step - loss: 0.2632 - accuracy: 0.9873 - val_loss: 0.6746 - val_accuracy: 0.8378 - lr: 1.2500e-04\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 9s 746ms/step - loss: 0.2595 - accuracy: 0.9886 - val_loss: 0.6633 - val_accuracy: 0.8441 - lr: 1.2500e-04\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 9s 737ms/step - loss: 0.2561 - accuracy: 0.9896 - val_loss: 0.6540 - val_accuracy: 0.8431 - lr: 1.2500e-04\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 9s 772ms/step - loss: 0.2552 - accuracy: 0.9885 - val_loss: 0.6591 - val_accuracy: 0.8420 - lr: 1.2500e-04\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 9s 771ms/step - loss: 0.2545 - accuracy: 0.9881 - val_loss: 0.6576 - val_accuracy: 0.8431 - lr: 1.2500e-04\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 9s 785ms/step - loss: 0.2522 - accuracy: 0.9886 - val_loss: 0.6581 - val_accuracy: 0.8438 - lr: 1.2500e-04\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 9s 738ms/step - loss: 0.2518 - accuracy: 0.9889 - val_loss: 0.6626 - val_accuracy: 0.8396 - lr: 1.2500e-04\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 9s 723ms/step - loss: 0.2472 - accuracy: 0.9894 - val_loss: 0.6526 - val_accuracy: 0.8424 - lr: 6.2500e-05\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 9s 709ms/step - loss: 0.2448 - accuracy: 0.9899 - val_loss: 0.6520 - val_accuracy: 0.8410 - lr: 6.2500e-05\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 10s 815ms/step - loss: 0.2431 - accuracy: 0.9898 - val_loss: 0.6493 - val_accuracy: 0.8413 - lr: 6.2500e-05\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 9s 691ms/step - loss: 0.2415 - accuracy: 0.9905 - val_loss: 0.6505 - val_accuracy: 0.8410 - lr: 6.2500e-05\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 9s 756ms/step - loss: 0.2410 - accuracy: 0.9900 - val_loss: 0.6506 - val_accuracy: 0.8389 - lr: 6.2500e-05\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 9s 765ms/step - loss: 0.2399 - accuracy: 0.9899 - val_loss: 0.6490 - val_accuracy: 0.8399 - lr: 6.2500e-05\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 9s 768ms/step - loss: 0.2379 - accuracy: 0.9908 - val_loss: 0.6507 - val_accuracy: 0.8399 - lr: 6.2500e-05\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 9s 770ms/step - loss: 0.2382 - accuracy: 0.9908 - val_loss: 0.6491 - val_accuracy: 0.8399 - lr: 6.2500e-05\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 9s 740ms/step - loss: 0.2353 - accuracy: 0.9913 - val_loss: 0.6492 - val_accuracy: 0.8382 - lr: 6.2500e-05\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 8s 635ms/step - loss: 0.2367 - accuracy: 0.9901 - val_loss: 0.6508 - val_accuracy: 0.8385 - lr: 6.2500e-05\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 10s 798ms/step - loss: 0.2344 - accuracy: 0.9905 - val_loss: 0.6474 - val_accuracy: 0.8385 - lr: 3.1250e-05\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 9s 774ms/step - loss: 0.2337 - accuracy: 0.9910 - val_loss: 0.6463 - val_accuracy: 0.8392 - lr: 3.1250e-05\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 8s 647ms/step - loss: 0.2339 - accuracy: 0.9905 - val_loss: 0.6447 - val_accuracy: 0.8392 - lr: 3.1250e-05\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 9s 733ms/step - loss: 0.2315 - accuracy: 0.9911 - val_loss: 0.6510 - val_accuracy: 0.8378 - lr: 3.1250e-05\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 8s 650ms/step - loss: 0.2309 - accuracy: 0.9919 - val_loss: 0.6472 - val_accuracy: 0.8403 - lr: 3.1250e-05\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 9s 744ms/step - loss: 0.2309 - accuracy: 0.9913 - val_loss: 0.6450 - val_accuracy: 0.8399 - lr: 3.1250e-05\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 9s 736ms/step - loss: 0.2309 - accuracy: 0.9911 - val_loss: 0.6458 - val_accuracy: 0.8368 - lr: 3.1250e-05\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 10s 808ms/step - loss: 0.2301 - accuracy: 0.9906 - val_loss: 0.6459 - val_accuracy: 0.8382 - lr: 3.1250e-05\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_, y_train_encoded, validation_data=(X_val_, y_val_encoded), epochs=100, batch_size=1024, callbacks=[early_stopping, lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss, val_loss = history.history['loss'], history.history['val_loss']\n",
    "\n",
    "plt.plot(loss, label='loss')\n",
    "plt.plot(val_loss, label='val_loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 2s 13ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.66      0.66       487\n",
      "           1       0.64      0.63      0.64       432\n",
      "           2       0.71      0.80      0.75      1211\n",
      "           3       0.54      0.52      0.53       293\n",
      "           4       0.80      0.70      0.75      1049\n",
      "           5       0.63      0.45      0.52       128\n",
      "\n",
      "    accuracy                           0.70      3600\n",
      "   macro avg       0.66      0.63      0.64      3600\n",
      "weighted avg       0.70      0.70      0.70      3600\n",
      "\n",
      "[[323  24  67  22  50   1]\n",
      " [ 38 274  60   4  44  12]\n",
      " [ 41  50 970  70  63  17]\n",
      " [ 20  12  90 153  18   0]\n",
      " [ 67  46 166  29 737   4]\n",
      " [  9  23  20   7  12  57]]\n",
      "0.6983333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "predictions = model.predict(X_test_std)\n",
    "prediction_labels = predictions.argmax(axis=1)\n",
    "print(classification_report(y_test_, prediction_labels))\n",
    "print(confusion_matrix(y_test_, prediction_labels))\n",
    "print(accuracy_score(y_test_, prediction_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2159\n",
      "1 1937\n",
      "2 5362\n",
      "3 1304\n",
      "4 4666\n",
      "5 572\n"
     ]
    }
   ],
   "source": [
    "unique_value, counts = np.unique(y_train, return_counts=True)\n",
    "for element, count in zip(unique_value, counts):\n",
    "    print(element, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 275\n",
      "1 224\n",
      "2 695\n",
      "3 159\n",
      "4 581\n",
      "5 66\n"
     ]
    }
   ],
   "source": [
    "unique_value, counts = np.unique(y_test, return_counts=True)\n",
    "for element, count in zip(unique_value, counts):\n",
    "    print(element, count)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have tried several dozens of times on this model: increasing and reducing the layers, increasing and reducing the neurons in each layer, tuning the regularization parameter, changing regularization, tuning the learning rate, batch size, *etc*.\n",
    "\n",
    "I also tried to experiment on the different input, a.k.a. using different representation of original text for model training, such as matrix obtained from spacy.load('en_core_web_md')(text). And finally I got this result with the tf_idf matrix representation for training the model while the scale of the model is large with nearly 34 million."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: FNN_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: FNN_model/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('FNN_model')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN, LSTM and GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 1000, 100)         1518600   \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 1024)              4608000   \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 512)               524800    \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 6)                 390       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,824,270\n",
      "Trainable params: 6,824,270\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "import math\n",
    "import tensorflow as tf\n",
    "\n",
    "# 数据处理\n",
    "tweets_train = df_train['tweet']\n",
    "tweet_test = df_test['tweet']\n",
    "labels_train = df_train['sentiment']\n",
    "labels_test = df_test['sentiment']\n",
    "\n",
    "verctorizer = TfidfVectorizer()\n",
    "X_train_tfidf = verctorizer.fit_transform(tweets_train)\n",
    "X_test_tfidf = verctorizer.transform(tweet_test)\n",
    "\n",
    "max_sequence_length = 1000\n",
    "X_train_padded = pad_sequences(X_train_tfidf.toarray(), maxlen=max_sequence_length)\n",
    "X_test_padded = pad_sequences(X_test_tfidf.toarray(), maxlen=max_sequence_length)\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train_padded = le.fit_transform(labels_train)\n",
    "y_test_padded = le.transform(labels_test)\n",
    "\n",
    "# Convert labels to categorical if needed\n",
    "# y_train_padded = to_categorical(y_train_padded)\n",
    "# y_test_padded = to_categorical(y_test_padded)\n",
    "\n",
    "num_classes = len(le.classes_)\n",
    "vocab_size = len(verctorizer.vocabulary_)\n",
    "embedding_dim = 100\n",
    "\n",
    "# 设置学习率与early_stopping\n",
    "def step_decay(epoch):\n",
    "    initial_lrate = 0.01\n",
    "    drop = 0.5\n",
    "    epochs_drop = 10.0\n",
    "    lrate = initial_lrate * math.pow(drop, math.floor((1 + epoch) / epochs_drop))\n",
    "    return lrate\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(step_decay)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', restore_best_weights=True, patience=5)\n",
    "\n",
    "# strategy = tf.distribute.OneDeviceStrategy(device='/gpu:0')\n",
    "# 搭建模型\n",
    "# with strategy.scope():\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim, input_length=max_sequence_length))\n",
    "model.add(LSTM(1024, recurrent_dropout=0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练模型\n",
    "history = model.fit(X_train_padded, y_train_padded, batch_size=512, epochs=100,\n",
    "                    validation_data=(X_test_padded, y_test_padded),\n",
    "                    callbacks=[early_stopping, lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, val_loos = history['loss'], history['val_loss']\n",
    "\n",
    "plt.plot(loss, label='Training loss')\n",
    "plt.plot(val_loos, label='Validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer based Pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet sentiment\n",
       "0                            i didnt feel humiliated   sadness\n",
       "1  i can go from feeling so hopeless to so damned...   sadness\n",
       "2   im grabbing a minute to post i feel greedy wrong     anger\n",
       "3  i am ever feeling nostalgic about the fireplac...      love\n",
       "4                               i am feeling grouchy     anger"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('./train.txt', header=None, delimiter=';')\n",
    "df_test = pd.read_csv('./test.txt', header=None, delimiter=';')\n",
    "df_train = df_train.rename(columns={0: 'tweet', 1: 'sentiment'})\n",
    "df_test = df_test.rename(columns={0: 'tweet', 1: 'sentiment'})\n",
    "df_train.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, BertTokenizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "encoded_input_train = tokenizer.batch_encode_plus(texts_train, padding=True, truncation=True, return_tensors='pt')\n",
    "input_ids_train = encoded_input_train['input_ids']\n",
    "attention_masks_train = encoded_input_train['attention_mask']\n",
    "\n",
    "labels_train = df_train['sentiment']\n",
    "le = LabelEncoder()\n",
    "labels_train =le.fit_transform(labels_train)\n",
    "labels_train = to_categorical(labels_train)\n",
    "labels_train = torch.tensor(labels_train)\n",
    "\n",
    "\n",
    "transformer_model = AutoModel.from_pretrained('bert-base-uncased')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "transformer_model.to(device)\n",
    "optimizer = torch.optim.Adam(transformer_model.parameters(), lr=1e-5)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "transformer_model.train()\n",
    "input_ids_train = input_ids_train.to(device)\n",
    "attention_masks_train = attention_masks_train.to(device)\n",
    "labels_train = labels_train.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0020, -0.0545, -0.0427,  ..., -0.0806, -0.0876,  0.0259],\n",
       "        [-0.0798, -0.0748,  0.0032,  ...,  0.0238,  0.0873, -0.0114],\n",
       "        [-0.0061, -0.0134,  0.0178,  ...,  0.0522,  0.0160, -0.0167],\n",
       "        [ 0.0459, -0.0031,  0.0880,  ...,  0.0709, -0.0803,  0.0415],\n",
       "        [ 0.0195, -0.0304, -0.0010,  ...,  0.0190, -0.0422,  0.0654],\n",
       "        [ 0.0330,  0.0297, -0.0718,  ...,  0.0068,  0.0588, -0.0725]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "transformer_model = AutoModel.from_pretrained('bert-base-uncased')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "transformer_model.to(device)\n",
    "optimizer = torch.optim.Adam(transformer_model.parameters(), lr=1e-5)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "texts_train = df_train['tweet']\n",
    "labels_train = df_train['sentiment']\n",
    "le = LabelEncoder()\n",
    "labels_train = le.fit_transform(labels_train)\n",
    "labels_train = to_categorical(labels_train)\n",
    "labels_train = torch.tensor(labels_train).to(device)\n",
    "\n",
    "# Tokenize texts_train\n",
    "encoded_inputs = tokenizer(texts_train.tolist(), padding=True, truncation=True, return_tensors='pt')\n",
    "input_ids_train = encoded_inputs['input_ids'].to(device)\n",
    "attention_masks_train = encoded_inputs['attention_mask'].to(device)\n",
    "\n",
    "train_dataset = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "transformer_model.train()\n",
    "\n",
    "linear_layer = nn.Linear(transformer_model.config.hidden_size, le.classes_.shape[0]).to(device)\n",
    "nn.init.xavier_uniform_(linear_layer.weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Average Loss: 0.3431227789670229\n",
      "Epoch 2 - Average Loss: 0.15944166499562562\n",
      "Epoch 3 - Average Loss: 0.07959097695350648\n",
      "Epoch 4 - Average Loss: 0.05580993509478867\n",
      "Epoch 5 - Average Loss: 0.04338084980705753\n",
      "Epoch 6 - Average Loss: 0.03838919259759132\n",
      "Epoch 7 - Average Loss: 0.03426969006942818\n",
      "Epoch 8 - Average Loss: 0.030790360981074627\n",
      "Epoch 9 - Average Loss: 0.027876388156437316\n",
      "Epoch 10 - Average Loss: 0.02630211615844746\n",
      "Epoch 11 - Average Loss: 0.02624506679715705\n",
      "Epoch 12 - Average Loss: 0.025121578735153888\n",
      "Epoch 13 - Average Loss: 0.023111631666950416\n",
      "Epoch 14 - Average Loss: 0.0223442898268695\n",
      "Epoch 15 - Average Loss: 0.02088869621325284\n",
      "Epoch 16 - Average Loss: 0.02109514506465348\n",
      "Epoch 17 - Average Loss: 0.018455659539700717\n",
      "Epoch 18 - Average Loss: 0.017144603587701566\n",
      "Epoch 19 - Average Loss: 0.017530029333669518\n",
      "Epoch 20 - Average Loss: 0.017526032913141535\n",
      "Epoch 21 - Average Loss: 0.016154191977955635\n",
      "Epoch 22 - Average Loss: 0.015543671893923602\n",
      "Epoch 23 - Average Loss: 0.014400973078576499\n",
      "Epoch 24 - Average Loss: 0.015483351661096094\n",
      "Epoch 25 - Average Loss: 0.01510167918575462\n",
      "Epoch 26 - Average Loss: 0.014666177272785717\n",
      "Epoch 27 - Average Loss: 0.013452183268545923\n",
      "Epoch 28 - Average Loss: 0.014083862124072767\n",
      "Epoch 29 - Average Loss: 0.011417762398523337\n",
      "Epoch 30 - Average Loss: 0.011542539221383777\n"
     ]
    }
   ],
   "source": [
    "accumulation_steps = 4  # Accumulate gradients over 4 batches\n",
    "total_losses = []\n",
    "for epoch in range(30):\n",
    "    total_loss = 0\n",
    "    for batch_idx, (batch_input_ids, batch_attention_masks, batch_labels) in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        batch_input_ids = batch_input_ids.to(device)\n",
    "        batch_attention_masks = batch_attention_masks.to(device)\n",
    "        batch_labels = batch_labels.to(device)\n",
    "\n",
    "        outputs = transformer_model(input_ids=batch_input_ids, attention_mask=batch_attention_masks)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        logits = linear_layer(pooled_output)\n",
    "\n",
    "        loss = loss_fn(logits, torch.argmax(batch_labels, dim=1))\n",
    "        loss = loss / accumulation_steps  # Scale the loss\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        if (batch_idx + 1) % accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    total_losses.append(total_loss / len(train_dataloader))\n",
    "    print(f\"Epoch {epoch + 1} - Average Loss: {total_loss / len(train_dataloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Tokenize the input test text and convert it to input tensors\n",
    "texts_test = df_test['tweet']\n",
    "labels_test = df_test['sentiment']\n",
    "le = LabelEncoder()\n",
    "labels_test = le.fit_transform(labels_test)\n",
    "labels_test = to_categorical(labels_test)\n",
    "labels_test = torch.tensor(labels_test).to(device)\n",
    "\n",
    "# Tokenize texts_test\n",
    "encoded_inputs = tokenizer(texts_test.tolist(), padding=True, truncation=True, return_tensors='pt')\n",
    "input_ids = encoded_inputs['input_ids'].to(device)\n",
    "attention_masks = encoded_inputs['attention_mask'].to(device)\n",
    "\n",
    "# Inference\n",
    "with torch.no_grad():\n",
    "    outputs = transformer_model(input_ids, attention_masks)\n",
    "    last_hidden_states = outputs.last_hidden_state\n",
    "    logits = linear_layer(last_hidden_states[:, 0, :])\n",
    "    probabilities = torch.softmax(logits, dim=1)\n",
    "    _, predicted_classes = torch.max(probabilities, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.0800\n",
      "Test F1-Score: 0.0870\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.01      0.00      0.00       275\n",
      "           1       0.02      0.06      0.03       224\n",
      "           2       0.64      0.08      0.15       695\n",
      "           3       0.23      0.50      0.32       159\n",
      "           4       0.11      0.01      0.02       581\n",
      "           5       0.00      0.02      0.00        66\n",
      "\n",
      "    accuracy                           0.08      2000\n",
      "   macro avg       0.17      0.11      0.09      2000\n",
      "weighted avg       0.28      0.08      0.09      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted_classes = predicted_classes.cpu().numpy()\n",
    "labels_test = torch.argmax(labels_test, dim=1).cpu().numpy()\n",
    "\n",
    "accuracy = accuracy_score(labels_test, predicted_classes)\n",
    "f1 = f1_score(labels_test, predicted_classes, average='weighted')\n",
    "classification_reports = classification_report(labels_test, predicted_classes)\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Test F1-Score: {f1:.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./models/Bert/BertBasedModelTokenizer\\\\tokenizer_config.json',\n",
       " './models/Bert/BertBasedModelTokenizer\\\\special_tokens_map.json',\n",
       " './models/Bert/BertBasedModelTokenizer\\\\vocab.txt',\n",
       " './models/Bert/BertBasedModelTokenizer\\\\added_tokens.json',\n",
       " './models/Bert/BertBasedModelTokenizer\\\\tokenizer.json')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Persistance a transfer learning pretrained model in PyTorch\n",
    "# Save the model state dict\n",
    "torch.save(transformer_model.state_dict(), './models/Bert/BertBasedModel.pth')\n",
    "# Save the tokenizer\n",
    "tokenizer.save_pretrained('./models/Bert/BertBasedModelTokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load transfer learning pretrained model in PyTorch\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "model =AutoModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Load the model weights\n",
    "model.load_state_dict(torch.load('./models/BertBasedModel.pth'))\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('./models/BertBasedModelTokenizer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define my transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "class TransformerClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_classes, num_layers, num_heads, dropout):\n",
    "        super(TransformerClassifier, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(embedding_dim, num_heads, dim_feedforward=hidden_dim, dropout=dropout),\n",
    "            num_layers=num_layers\n",
    "        )\n",
    "        self.fc = nn.Linear(embedding_dim, num_classes)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        embedded = self.embedding(input_ids)\n",
    "        encoded = self.transformer_encoder(embedded.transpose(0, 1), src_key_padding_mask=attention_mask)\n",
    "        pooled = encoded.mean(dim=0)\n",
    "        logits = self.fc(pooled)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "only bool and floating types of src_key_padding_mask are supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 40\u001b[0m\n\u001b[0;32m     37\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m     39\u001b[0m \u001b[39m# Forward pass\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m logits \u001b[39m=\u001b[39m model(batch_input_ids, batch_attention_masks)\n\u001b[0;32m     41\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(logits, torch\u001b[39m.\u001b[39margmax(batch_labels, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[0;32m     43\u001b[0m \u001b[39m# Backward pass and optimization\u001b[39;00m\n",
      "File \u001b[1;32me:\\Anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[24], line 19\u001b[0m, in \u001b[0;36mTransformerClassifier.forward\u001b[1;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, input_ids, attention_mask):\n\u001b[0;32m     18\u001b[0m     embedded \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding(input_ids)\n\u001b[1;32m---> 19\u001b[0m     encoded \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransformer_encoder(embedded\u001b[39m.\u001b[39;49mtranspose(\u001b[39m0\u001b[39;49m, \u001b[39m1\u001b[39;49m), src_key_padding_mask\u001b[39m=\u001b[39;49mattention_mask)\n\u001b[0;32m     20\u001b[0m     pooled \u001b[39m=\u001b[39m encoded\u001b[39m.\u001b[39mmean(dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m     21\u001b[0m     logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc(pooled)\n",
      "File \u001b[1;32me:\\Anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32me:\\Anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:214\u001b[0m, in \u001b[0;36mTransformerEncoder.forward\u001b[1;34m(self, src, mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[0;32m    196\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[0;32m    197\u001b[0m         src: Tensor,\n\u001b[0;32m    198\u001b[0m         mask: Optional[Tensor] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    199\u001b[0m         src_key_padding_mask: Optional[Tensor] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    200\u001b[0m         is_causal: Optional[\u001b[39mbool\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m    201\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Pass the input through the encoder layers in turn.\u001b[39;00m\n\u001b[0;32m    202\u001b[0m \n\u001b[0;32m    203\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[39m        see the docs in Transformer class.\u001b[39;00m\n\u001b[0;32m    213\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 214\u001b[0m     src_key_padding_mask \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39;49m_canonical_mask(\n\u001b[0;32m    215\u001b[0m         mask\u001b[39m=\u001b[39;49msrc_key_padding_mask,\n\u001b[0;32m    216\u001b[0m         mask_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39msrc_key_padding_mask\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    217\u001b[0m         other_type\u001b[39m=\u001b[39;49mF\u001b[39m.\u001b[39;49m_none_or_dtype(mask),\n\u001b[0;32m    218\u001b[0m         other_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mmask\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    219\u001b[0m         target_type\u001b[39m=\u001b[39;49msrc\u001b[39m.\u001b[39;49mdtype\n\u001b[0;32m    220\u001b[0m     )\n\u001b[0;32m    222\u001b[0m     mask \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39m_canonical_mask(\n\u001b[0;32m    223\u001b[0m         mask\u001b[39m=\u001b[39mmask,\n\u001b[0;32m    224\u001b[0m         mask_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmask\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    228\u001b[0m         check_other\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    229\u001b[0m     )\n\u001b[0;32m    231\u001b[0m     output \u001b[39m=\u001b[39m src\n",
      "File \u001b[1;32me:\\Anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\functional.py:4995\u001b[0m, in \u001b[0;36m_canonical_mask\u001b[1;34m(mask, mask_name, other_type, other_name, target_type, check_other)\u001b[0m\n\u001b[0;32m   4993\u001b[0m _mask_is_float \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mis_floating_point(mask)\n\u001b[0;32m   4994\u001b[0m \u001b[39mif\u001b[39;00m _mask_dtype \u001b[39m!=\u001b[39m torch\u001b[39m.\u001b[39mbool \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m _mask_is_float:\n\u001b[1;32m-> 4995\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\n\u001b[0;32m   4996\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39monly bool and floating types of \u001b[39m\u001b[39m{\u001b[39;00mmask_name\u001b[39m}\u001b[39;00m\u001b[39m are supported\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   4997\u001b[0m \u001b[39mif\u001b[39;00m check_other \u001b[39mand\u001b[39;00m other_type \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   4998\u001b[0m     \u001b[39mif\u001b[39;00m _mask_dtype \u001b[39m!=\u001b[39m other_type:\n",
      "\u001b[1;31mAssertionError\u001b[0m: only bool and floating types of src_key_padding_mask are supported"
     ]
    }
   ],
   "source": [
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Define hyperparameters\n",
    "vocab_size = len(tokenizer)\n",
    "embedding_dim = 128\n",
    "hidden_dim = 256\n",
    "num_classes = 6\n",
    "num_layers = 2\n",
    "num_heads = 4\n",
    "dropout = 0.2\n",
    "learning_rate = 1e-3\n",
    "batch_size = 16\n",
    "num_epochs = 30\n",
    "\n",
    "model = TransformerClassifier(vocab_size, embedding_dim, hidden_dim, num_classes, num_layers, num_heads, dropout)\n",
    "model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Create DataLoader\n",
    "train_dataset = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for batch_input_ids, batch_attention_masks, batch_labels in train_dataloader:\n",
    "        # Move batch tensors to device\n",
    "        batch_input_ids = batch_input_ids.to(device)\n",
    "        batch_attention_masks = batch_attention_masks.to(device)\n",
    "        batch_labels = batch_labels.to(device)\n",
    "        \n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        logits = model(batch_input_ids, batch_attention_masks)\n",
    "        loss = loss_fn(logits, torch.argmax(batch_labels, dim=1))\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    average_loss = total_loss / len(train_dataloader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {average_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model persistance\n",
    "\n",
    "torch.save(model.state_dict(), './models/MyTransformer.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "\n",
    "model_new = TransformerClassifier(vocab_size, \n",
    "                                  embedding_dim, \n",
    "                                  hidden_dim, \n",
    "                                  num_classes, \n",
    "                                  num_layers, \n",
    "                                  num_heads, \n",
    "                                  dropout)\n",
    "\n",
    "model.load_state_dict(torch.load('/models/BertBasedModel.pth'))\n",
    "model.to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load models:\n",
    "`my_model = tf.keras.models.load_model('my_model')`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
