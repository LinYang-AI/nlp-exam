{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Students: Lin Yang, Mariia Isaieva, Martin Sejas <center>NLP Course <br><small>Graded Project Instructions <br>Spring 2023</small></center>\n",
    "\n",
    "About the dataset: \n",
    "\n",
    "List of tweet texts with emotion labels like joy, sadness, fear, anger... \n",
    "Dataset is split into train, test and validation sets for building the machine learning model. At first, you are \n",
    "given only train and test sets. The validation one will be given in the end of the project for you to check \n",
    "the final performance of your algorithm (to make sure there is no overfitting over the test data). \n",
    "You can work on this project on group of one, two or three students. This exercise is mandatory, not \n",
    "giving it back is equivalent to getting to lowest grade. \n",
    "Goal: \n",
    "\n",
    "• Train different kind of models able to classify each text according to the sentiment mainly present \n",
    "in it \n",
    "\n",
    "• Compare the results of your different models and try to analyze and explain the differences\n",
    "\n",
    "Train different classification models relying mainly on \n",
    "\n",
    "1. A Fully Connected Neural Network (see Course 2) 5 points \n",
    "\n",
    "2. A Recurrent Neural Network, based on LSTM or GRU (see Course 3) 5 points \n",
    "\n",
    "3. A fine-tuned Transformer Architecture from a pretrained model that can be found on sites \n",
    "like HuggingFace (see Course 4) 5 points \n",
    "\n",
    "4. Compare the different models to find the best approach and try to duplicate it on a “real life” \n",
    "text classification approach (this new “real life” dataset will be given to you soon) 5 points"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and Preprocessing the data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is a tweets sentiment dataset, it's quite straightforward, there are only 2 columns, the tweet itself, and the sentiment attached to it. We have been provided a train set and a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet sentiment\n",
       "0                            i didnt feel humiliated   sadness\n",
       "1  i can go from feeling so hopeless to so damned...   sadness\n",
       "2   im grabbing a minute to post i feel greedy wrong     anger\n",
       "3  i am ever feeling nostalgic about the fireplac...      love\n",
       "4                               i am feeling grouchy     anger"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('./train.txt', header=None, delimiter=';')\n",
    "df_test = pd.read_csv('./test.txt', header=None, delimiter=';')\n",
    "df_train = df_train.rename(columns={0: 'tweet', 1: 'sentiment'})\n",
    "df_test = df_test.rename(columns={0: 'tweet', 1: 'sentiment'})\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After loading our dataset we can see the class (sentiment) distribution of our tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(sentiment\n",
       " joy         5362\n",
       " sadness     4666\n",
       " anger       2159\n",
       " fear        1937\n",
       " love        1304\n",
       " surprise     572\n",
       " Name: count, dtype: int64,\n",
       " (16000, 2))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['sentiment'].value_counts(), df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(sentiment\n",
       " joy         695\n",
       " sadness     581\n",
       " anger       275\n",
       " fear        224\n",
       " love        159\n",
       " surprise     66\n",
       " Name: count, dtype: int64,\n",
       " (2000, 2))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['sentiment'].value_counts(), df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see here that there are class inbalances. Especially regarding joy and surprise.\n",
    "\n",
    "We will also separate each tweet from it's label to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_train = df_train['tweet']\n",
    "texts_test = df_test['tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4, 0, ..., 2, 0, 4])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(df_train['sentiment'])\n",
    "y_test = le.transform(df_test['sentiment'])\n",
    "y_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing the tweets (Lemmetizing) with the Spacy library."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmetization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to be using the famous [Spacy](https://spacy.io/) Library for tokenization, it's the best performing one in terms of computational cost and performance.\n",
    "\n",
    "We will be loading the english core *medium* dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To have spacy working please make sure to run the following commands. \n",
    "\n",
    "```bash\n",
    "pip install spacy\n",
    "```\n",
    "\n",
    "Once the package has been installed, make sure to download the language model, in our case, *en-core-web-md* will be used, and can be downloaded by the following command. \n",
    "\n",
    "```bash \n",
    "python -m spacy download en_core_web_md\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "\n",
    "#Function to tokenize\n",
    "def preprocess_text(text):\n",
    "    #every tweet will become a document \n",
    "    doc = nlp(text)\n",
    "    \n",
    "    #Creating a list of tokens by lemmatizing the words, filtering stop words.\n",
    "    tokens = [token.lemma_.lower().strip() for token in doc if not token.is_stop]\n",
    "    \n",
    "    #Join all the words in one sentence\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the *preprocess_text* function, we will pre-process the tweet text, and with that we can apply it to both of our dataframes as a new series, and see the output.\n",
    "\n",
    "*Warning this cell takes over 2 minutes to run!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "      <td>not feel humiliate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>feel hopeless damn hopeful care awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>anger</td>\n",
       "      <td>m grab minute post feel greedy wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>love</td>\n",
       "      <td>feel nostalgic fireplace know property</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>anger</td>\n",
       "      <td>feel grouchy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet sentiment  \\\n",
       "0                            i didnt feel humiliated   sadness   \n",
       "1  i can go from feeling so hopeless to so damned...   sadness   \n",
       "2   im grabbing a minute to post i feel greedy wrong     anger   \n",
       "3  i am ever feeling nostalgic about the fireplac...      love   \n",
       "4                               i am feeling grouchy     anger   \n",
       "\n",
       "                                processed  \n",
       "0                      not feel humiliate  \n",
       "1   feel hopeless damn hopeful care awake  \n",
       "2    m grab minute post feel greedy wrong  \n",
       "3  feel nostalgic fireplace know property  \n",
       "4                            feel grouchy  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['processed'] = df_train['tweet'].apply(preprocess_text)\n",
    "df_test['processed'] = df_test['tweet'].apply(preprocess_text)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1- Fully Connected Neural Network(5 Points)\n",
    "### TF-IDF and Latent DirichletAllocation embedding for Sequential Neural Network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using sklearn's TFidfVectorizer to be able to process the data and feed it into our Neural Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000, 5587)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
    "\n",
    "dtm_train = tfidf.fit_transform(df_train['processed'])\n",
    "dtm_test = tfidf.transform(df_test['processed'])\n",
    "dtm_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the training set to training and validation sets for training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16000, 5587)\n",
      "(12800, 5587)\n",
      "(3200, 5587)\n",
      "(2000, 5587)\n",
      "(12800,)\n",
      "(3200,)\n",
      "(2000,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_ = dtm_train.toarray()\n",
    "X_test_ = dtm_test.toarray()\n",
    "y_train_ = y_train\n",
    "y_test_ = y_test\n",
    "# X_train_ = np.vstack((X_train_, X_test_))\n",
    "# y_train_ = np.concatenate((y_train, y_test))\n",
    "\n",
    "print(X_train_.shape)\n",
    "\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "\n",
    "\n",
    "# X_train_, X_test_, y_train, y_test_ = train_test_split(X_train_, y_train, test_size=0.2, random_state=42, stratify=y_train)\n",
    "X_train_, X_val_, y_train_, y_val_ = train_test_split(X_train_, y_train, test_size=0.2, random_state=42, stratify=y_train)\n",
    "\n",
    "print(X_train_.shape)\n",
    "print(X_val_.shape)\n",
    "print(X_test_.shape)\n",
    "print(y_train_.shape)\n",
    "print(y_val_.shape)\n",
    "print(y_test_.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode the label in one hot encoding fashion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12800, 6), (2000, 6), (3200, 6))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "y_train_encoded = to_categorical(y_train_)\n",
    "y_test_encoded = to_categorical(y_test_)\n",
    "y_val_encoded = to_categorical(y_val_)\n",
    "y_train_encoded.shape, y_test_encoded.shape, y_val_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0.]], dtype=float32),\n",
       " (12800, 6))"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_encoded, y_train_encoded.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Experiements No need to check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_tweets_sentiment(df_train):\n",
    "#     i = 0\n",
    "#     dict_label = []\n",
    "#     list_embed = []    \n",
    "#     size_data = df_train.shape[0]\n",
    "\n",
    "#     for sentence in list(df_train.itertuples())[0:size_data]:\n",
    "#         text_embed =np.ndarray.flatten(nlp(sentence.tweet).vector)\n",
    "#         observed_sentiment = sentence.sentiment\n",
    "#         if observed_sentiment == 'joy':\n",
    "#             label = 0.0\n",
    "#         elif observed_sentiment == 'sadness':\n",
    "#             label = 1.0\n",
    "#         elif observed_sentiment == 'anger':\n",
    "#             label = 2.0\n",
    "#         elif observed_sentiment == 'fear':\n",
    "#             label = 3.0\n",
    "#         elif observed_sentiment == 'love':\n",
    "#             label = 4.0\n",
    "#         else:\n",
    "#             label = 5.0\n",
    "#         dict_label.append(label)\n",
    "#         list_embed.append(np.array([text_embed]))\n",
    "#         i += 1\n",
    "#     return dict_label, list_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_set = get_tweets_sentiment(df_train)\n",
    "# test_set = get_tweets_sentiment(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train_label = training_set[0]\n",
    "# X_train_embed = np.array(training_set[1])\n",
    "\n",
    "# y_test_label = test_set[0]\n",
    "# X_test_embed = np.array(test_set[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = pd.DataFrame.from_dict(X_train_embed_dict, orient='index')\n",
    "# X_test = pd.DataFrame.from_dict(X_test_embed_dict, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train = pd.DataFrame({'sentiment': pd.Series(y_train_label)})\n",
    "# y_test = pd.DataFrame({'sentiment': pd.Series(y_test_label)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = X_train.join(y_train)\n",
    "# X_test = X_test.join(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train = X_train['sentiment']\n",
    "# X_train = X_train.drop('sentiment', axis=1)\n",
    "\n",
    "# y_test = X_test['sentiment']\n",
    "# X_test = X_test.drop('sentiment', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16000, 6)\n"
     ]
    }
   ],
   "source": [
    "# from keras.utils import to_categorical\n",
    "\n",
    "# y_train_encoded = to_categorical(y_train)\n",
    "# y_test_encoded = to_categorical(y_test)\n",
    "# print(y_train_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-11.600116729736328, 13.568775177001953)"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# min_num = np.inf\n",
    "# max_num = -np.inf\n",
    "\n",
    "# for i in range(300):\n",
    "#     if min(X_train.iloc[:, i]) < min_num:\n",
    "#         min_num = min(X_train.iloc[:, i])\n",
    "#     if max(X_train.iloc[:, i]) > max_num:\n",
    "#         max_num = max(X_train.iloc[:, i])\n",
    "# min_num, max_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "# std = StandardScaler()\n",
    "\n",
    "# X_train = std.fit_transform(X_train)\n",
    "# X_test = std.transform(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully connect NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the fully connected NN with tensorflow.\n",
    "\n",
    "The first layer has a high number of nerons because the input data set has `>5000` features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_46 (Dense)            (None, 4096)              22888448  \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 2048)              8390656   \n",
      "                                                                 \n",
      " dense_48 (Dense)            (None, 1024)              2098176   \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_49 (Dense)            (None, 64)                65600     \n",
      "                                                                 \n",
      " dense_50 (Dense)            (None, 6)                 390       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33443270 (127.58 MB)\n",
      "Trainable params: 33443270 (127.58 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras import Sequential\n",
    "import tensorflow as tf\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(4096, activation='selu', kernel_initializer='lecun_normal', input_shape=(X_train_.shape[1],), kernel_regularizer=tf.keras.regularizers.l2(0.01)))\n",
    "model.add(Dense(2048, activation='selu', kernel_initializer='lecun_normal', kernel_regularizer=tf.keras.regularizers.l2(0.01)))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(1024, activation='selu', kernel_initializer='lecun_normal', kernel_regularizer=tf.keras.regularizers.l2(0.1)))\n",
    "model.add(Dropout(0.2))\n",
    "# model.add(Dense(512, activation='selu', kernel_initializer='lecun_normal', ))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(128, activation='selu', kernel_initializer='lecun_normal', ))\n",
    "model.add(Dense(64, activation='selu',))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "\n",
    "model.layers[-1].bias.assign(class_weights)\n",
    "model.compile(optimizer='Adam', loss=tf.losses.categorical_crossentropy, metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the early stopping condition and use a dynamic learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.callbacks import EarlyStopping, CallbackList, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "def step_decay(epoch):\n",
    "    initial_lrate = 0.001\n",
    "    drop = 0.5\n",
    "    epochs_drop = 10.0\n",
    "    lrate = initial_lrate * math.pow(drop, math.floor((1 + epoch) / epochs_drop))\n",
    "    return lrate\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(step_decay)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', restore_best_weights=True, patience=5) # "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "13/13 [==============================] - 5s 316ms/step - loss: 104.2934 - accuracy: 0.4451 - val_loss: 48.7232 - val_accuracy: 0.7081 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 4s 277ms/step - loss: 28.9494 - accuracy: 0.7758 - val_loss: 13.0855 - val_accuracy: 0.8059 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 4s 289ms/step - loss: 8.0179 - accuracy: 0.8298 - val_loss: 4.0728 - val_accuracy: 0.8191 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 4s 330ms/step - loss: 2.7305 - accuracy: 0.8621 - val_loss: 1.7581 - val_accuracy: 0.8281 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 4s 294ms/step - loss: 1.3600 - accuracy: 0.8773 - val_loss: 1.1855 - val_accuracy: 0.8344 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 4s 288ms/step - loss: 1.0211 - accuracy: 0.8838 - val_loss: 1.0545 - val_accuracy: 0.8363 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 4s 297ms/step - loss: 0.9324 - accuracy: 0.8887 - val_loss: 1.0107 - val_accuracy: 0.8316 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 4s 304ms/step - loss: 0.8922 - accuracy: 0.8894 - val_loss: 0.9689 - val_accuracy: 0.8472 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 4s 311ms/step - loss: 0.8488 - accuracy: 0.8952 - val_loss: 0.9553 - val_accuracy: 0.8378 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 3s 259ms/step - loss: 0.7337 - accuracy: 0.9361 - val_loss: 0.9068 - val_accuracy: 0.8481 - lr: 5.0000e-04\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 3s 265ms/step - loss: 0.6780 - accuracy: 0.9437 - val_loss: 0.8659 - val_accuracy: 0.8500 - lr: 5.0000e-04\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - 4s 323ms/step - loss: 0.6543 - accuracy: 0.9439 - val_loss: 0.8565 - val_accuracy: 0.8503 - lr: 5.0000e-04\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 5s 366ms/step - loss: 0.6360 - accuracy: 0.9466 - val_loss: 0.8472 - val_accuracy: 0.8447 - lr: 5.0000e-04\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - 4s 295ms/step - loss: 0.6194 - accuracy: 0.9521 - val_loss: 0.8357 - val_accuracy: 0.8453 - lr: 5.0000e-04\n",
      "Epoch 15/100\n",
      "13/13 [==============================] - 4s 272ms/step - loss: 0.6121 - accuracy: 0.9534 - val_loss: 0.8356 - val_accuracy: 0.8522 - lr: 5.0000e-04\n",
      "Epoch 16/100\n",
      "13/13 [==============================] - 4s 303ms/step - loss: 0.6022 - accuracy: 0.9534 - val_loss: 0.8523 - val_accuracy: 0.8425 - lr: 5.0000e-04\n",
      "Epoch 17/100\n",
      "13/13 [==============================] - 4s 315ms/step - loss: 0.5995 - accuracy: 0.9512 - val_loss: 0.8240 - val_accuracy: 0.8503 - lr: 5.0000e-04\n",
      "Epoch 18/100\n",
      "13/13 [==============================] - 4s 278ms/step - loss: 0.5822 - accuracy: 0.9536 - val_loss: 0.8232 - val_accuracy: 0.8444 - lr: 5.0000e-04\n",
      "Epoch 19/100\n",
      "13/13 [==============================] - 4s 327ms/step - loss: 0.5676 - accuracy: 0.9584 - val_loss: 0.8100 - val_accuracy: 0.8475 - lr: 5.0000e-04\n",
      "Epoch 20/100\n",
      "13/13 [==============================] - 5s 391ms/step - loss: 0.5400 - accuracy: 0.9660 - val_loss: 0.7938 - val_accuracy: 0.8491 - lr: 2.5000e-04\n",
      "Epoch 21/100\n",
      "13/13 [==============================] - 4s 301ms/step - loss: 0.5204 - accuracy: 0.9711 - val_loss: 0.7885 - val_accuracy: 0.8509 - lr: 2.5000e-04\n",
      "Epoch 22/100\n",
      "13/13 [==============================] - 4s 315ms/step - loss: 0.5125 - accuracy: 0.9724 - val_loss: 0.7845 - val_accuracy: 0.8472 - lr: 2.5000e-04\n",
      "Epoch 23/100\n",
      "13/13 [==============================] - 4s 334ms/step - loss: 0.5081 - accuracy: 0.9719 - val_loss: 0.7833 - val_accuracy: 0.8500 - lr: 2.5000e-04\n",
      "Epoch 24/100\n",
      "13/13 [==============================] - 4s 292ms/step - loss: 0.5034 - accuracy: 0.9720 - val_loss: 0.7869 - val_accuracy: 0.8472 - lr: 2.5000e-04\n",
      "Epoch 25/100\n",
      "13/13 [==============================] - 4s 327ms/step - loss: 0.4971 - accuracy: 0.9737 - val_loss: 0.7724 - val_accuracy: 0.8484 - lr: 2.5000e-04\n",
      "Epoch 26/100\n",
      "13/13 [==============================] - 4s 313ms/step - loss: 0.4976 - accuracy: 0.9732 - val_loss: 0.7728 - val_accuracy: 0.8472 - lr: 2.5000e-04\n",
      "Epoch 27/100\n",
      "13/13 [==============================] - 5s 369ms/step - loss: 0.4900 - accuracy: 0.9732 - val_loss: 0.7722 - val_accuracy: 0.8453 - lr: 2.5000e-04\n",
      "Epoch 28/100\n",
      "13/13 [==============================] - 4s 301ms/step - loss: 0.4910 - accuracy: 0.9718 - val_loss: 0.7819 - val_accuracy: 0.8425 - lr: 2.5000e-04\n",
      "Epoch 29/100\n",
      "13/13 [==============================] - 6s 432ms/step - loss: 0.4868 - accuracy: 0.9723 - val_loss: 0.7683 - val_accuracy: 0.8481 - lr: 2.5000e-04\n",
      "Epoch 30/100\n",
      "13/13 [==============================] - 5s 408ms/step - loss: 0.4695 - accuracy: 0.9773 - val_loss: 0.7654 - val_accuracy: 0.8450 - lr: 1.2500e-04\n",
      "Epoch 31/100\n",
      "13/13 [==============================] - 6s 439ms/step - loss: 0.4642 - accuracy: 0.9765 - val_loss: 0.7609 - val_accuracy: 0.8459 - lr: 1.2500e-04\n",
      "Epoch 32/100\n",
      "13/13 [==============================] - 5s 369ms/step - loss: 0.4621 - accuracy: 0.9795 - val_loss: 0.7624 - val_accuracy: 0.8441 - lr: 1.2500e-04\n",
      "Epoch 33/100\n",
      "13/13 [==============================] - 6s 495ms/step - loss: 0.4630 - accuracy: 0.9782 - val_loss: 0.7607 - val_accuracy: 0.8453 - lr: 1.2500e-04\n",
      "Epoch 34/100\n",
      "13/13 [==============================] - 8s 598ms/step - loss: 0.4658 - accuracy: 0.9785 - val_loss: 0.7572 - val_accuracy: 0.8456 - lr: 1.2500e-04\n",
      "Epoch 35/100\n",
      "13/13 [==============================] - 7s 524ms/step - loss: 0.4532 - accuracy: 0.9780 - val_loss: 0.7538 - val_accuracy: 0.8472 - lr: 1.2500e-04\n",
      "Epoch 36/100\n",
      "13/13 [==============================] - 6s 484ms/step - loss: 0.4529 - accuracy: 0.9773 - val_loss: 0.7558 - val_accuracy: 0.8481 - lr: 1.2500e-04\n",
      "Epoch 37/100\n",
      "13/13 [==============================] - 5s 383ms/step - loss: 0.4508 - accuracy: 0.9766 - val_loss: 0.7572 - val_accuracy: 0.8456 - lr: 1.2500e-04\n",
      "Epoch 38/100\n",
      "13/13 [==============================] - 6s 442ms/step - loss: 0.4471 - accuracy: 0.9780 - val_loss: 0.7504 - val_accuracy: 0.8453 - lr: 1.2500e-04\n",
      "Epoch 39/100\n",
      "13/13 [==============================] - 5s 380ms/step - loss: 0.4464 - accuracy: 0.9795 - val_loss: 0.7507 - val_accuracy: 0.8447 - lr: 1.2500e-04\n",
      "Epoch 40/100\n",
      "13/13 [==============================] - 6s 457ms/step - loss: 0.4396 - accuracy: 0.9800 - val_loss: 0.7493 - val_accuracy: 0.8459 - lr: 6.2500e-05\n",
      "Epoch 41/100\n",
      "13/13 [==============================] - 6s 469ms/step - loss: 0.4382 - accuracy: 0.9794 - val_loss: 0.7480 - val_accuracy: 0.8466 - lr: 6.2500e-05\n",
      "Epoch 42/100\n",
      "13/13 [==============================] - 5s 361ms/step - loss: 0.4376 - accuracy: 0.9808 - val_loss: 0.7460 - val_accuracy: 0.8459 - lr: 6.2500e-05\n",
      "Epoch 43/100\n",
      "13/13 [==============================] - 6s 458ms/step - loss: 0.4331 - accuracy: 0.9809 - val_loss: 0.7454 - val_accuracy: 0.8466 - lr: 6.2500e-05\n",
      "Epoch 44/100\n",
      "13/13 [==============================] - 6s 418ms/step - loss: 0.4315 - accuracy: 0.9803 - val_loss: 0.7456 - val_accuracy: 0.8444 - lr: 6.2500e-05\n",
      "Epoch 45/100\n",
      "13/13 [==============================] - 7s 531ms/step - loss: 0.4314 - accuracy: 0.9810 - val_loss: 0.7445 - val_accuracy: 0.8462 - lr: 6.2500e-05\n",
      "Epoch 46/100\n",
      "13/13 [==============================] - 5s 406ms/step - loss: 0.4314 - accuracy: 0.9803 - val_loss: 0.7438 - val_accuracy: 0.8447 - lr: 6.2500e-05\n",
      "Epoch 47/100\n",
      "13/13 [==============================] - 6s 446ms/step - loss: 0.4280 - accuracy: 0.9809 - val_loss: 0.7430 - val_accuracy: 0.8447 - lr: 6.2500e-05\n",
      "Epoch 48/100\n",
      "13/13 [==============================] - 4s 331ms/step - loss: 0.4278 - accuracy: 0.9797 - val_loss: 0.7446 - val_accuracy: 0.8462 - lr: 6.2500e-05\n",
      "Epoch 49/100\n",
      "13/13 [==============================] - 5s 425ms/step - loss: 0.4280 - accuracy: 0.9808 - val_loss: 0.7432 - val_accuracy: 0.8444 - lr: 6.2500e-05\n",
      "Epoch 50/100\n",
      "13/13 [==============================] - 6s 458ms/step - loss: 0.4223 - accuracy: 0.9814 - val_loss: 0.7417 - val_accuracy: 0.8441 - lr: 3.1250e-05\n",
      "Epoch 51/100\n",
      "13/13 [==============================] - 6s 452ms/step - loss: 0.4238 - accuracy: 0.9812 - val_loss: 0.7415 - val_accuracy: 0.8462 - lr: 3.1250e-05\n",
      "Epoch 52/100\n",
      "13/13 [==============================] - 6s 456ms/step - loss: 0.4217 - accuracy: 0.9823 - val_loss: 0.7422 - val_accuracy: 0.8431 - lr: 3.1250e-05\n",
      "Epoch 53/100\n",
      "13/13 [==============================] - 5s 387ms/step - loss: 0.4203 - accuracy: 0.9820 - val_loss: 0.7420 - val_accuracy: 0.8450 - lr: 3.1250e-05\n",
      "Epoch 54/100\n",
      "13/13 [==============================] - 6s 426ms/step - loss: 0.4192 - accuracy: 0.9820 - val_loss: 0.7401 - val_accuracy: 0.8456 - lr: 3.1250e-05\n",
      "Epoch 55/100\n",
      "13/13 [==============================] - 7s 518ms/step - loss: 0.4194 - accuracy: 0.9823 - val_loss: 0.7396 - val_accuracy: 0.8462 - lr: 3.1250e-05\n",
      "Epoch 56/100\n",
      "13/13 [==============================] - 7s 512ms/step - loss: 0.4253 - accuracy: 0.9825 - val_loss: 0.7395 - val_accuracy: 0.8462 - lr: 3.1250e-05\n",
      "Epoch 57/100\n",
      "13/13 [==============================] - 8s 669ms/step - loss: 0.4181 - accuracy: 0.9824 - val_loss: 0.7399 - val_accuracy: 0.8444 - lr: 3.1250e-05\n",
      "Epoch 58/100\n",
      "13/13 [==============================] - 8s 585ms/step - loss: 0.4226 - accuracy: 0.9834 - val_loss: 0.7383 - val_accuracy: 0.8450 - lr: 3.1250e-05\n",
      "Epoch 59/100\n",
      "13/13 [==============================] - 6s 477ms/step - loss: 0.4168 - accuracy: 0.9817 - val_loss: 0.7386 - val_accuracy: 0.8453 - lr: 3.1250e-05\n",
      "Epoch 60/100\n",
      "13/13 [==============================] - 5s 354ms/step - loss: 0.4181 - accuracy: 0.9815 - val_loss: 0.7384 - val_accuracy: 0.8438 - lr: 1.5625e-05\n",
      "Epoch 61/100\n",
      "13/13 [==============================] - 6s 478ms/step - loss: 0.4156 - accuracy: 0.9819 - val_loss: 0.7377 - val_accuracy: 0.8444 - lr: 1.5625e-05\n",
      "Epoch 62/100\n",
      "13/13 [==============================] - 5s 360ms/step - loss: 0.4143 - accuracy: 0.9815 - val_loss: 0.7377 - val_accuracy: 0.8450 - lr: 1.5625e-05\n",
      "Epoch 63/100\n",
      "13/13 [==============================] - 6s 496ms/step - loss: 0.4141 - accuracy: 0.9828 - val_loss: 0.7376 - val_accuracy: 0.8450 - lr: 1.5625e-05\n",
      "Epoch 64/100\n",
      "13/13 [==============================] - 6s 453ms/step - loss: 0.4145 - accuracy: 0.9816 - val_loss: 0.7378 - val_accuracy: 0.8456 - lr: 1.5625e-05\n",
      "Epoch 65/100\n",
      "13/13 [==============================] - 6s 451ms/step - loss: 0.4138 - accuracy: 0.9823 - val_loss: 0.7376 - val_accuracy: 0.8453 - lr: 1.5625e-05\n",
      "Epoch 66/100\n",
      "13/13 [==============================] - 6s 461ms/step - loss: 0.4135 - accuracy: 0.9813 - val_loss: 0.7382 - val_accuracy: 0.8438 - lr: 1.5625e-05\n",
      "Epoch 67/100\n",
      "13/13 [==============================] - 5s 373ms/step - loss: 0.4132 - accuracy: 0.9820 - val_loss: 0.7385 - val_accuracy: 0.8438 - lr: 1.5625e-05\n",
      "Epoch 68/100\n",
      "13/13 [==============================] - 5s 378ms/step - loss: 0.4123 - accuracy: 0.9818 - val_loss: 0.7364 - val_accuracy: 0.8447 - lr: 1.5625e-05\n",
      "Epoch 69/100\n",
      "13/13 [==============================] - 5s 369ms/step - loss: 0.4117 - accuracy: 0.9819 - val_loss: 0.7371 - val_accuracy: 0.8450 - lr: 1.5625e-05\n",
      "Epoch 70/100\n",
      "13/13 [==============================] - 5s 364ms/step - loss: 0.4112 - accuracy: 0.9822 - val_loss: 0.7365 - val_accuracy: 0.8444 - lr: 7.8125e-06\n",
      "Epoch 71/100\n",
      "13/13 [==============================] - 5s 360ms/step - loss: 0.4118 - accuracy: 0.9820 - val_loss: 0.7366 - val_accuracy: 0.8444 - lr: 7.8125e-06\n",
      "Epoch 72/100\n",
      "13/13 [==============================] - 5s 404ms/step - loss: 0.4135 - accuracy: 0.9823 - val_loss: 0.7363 - val_accuracy: 0.8447 - lr: 7.8125e-06\n",
      "Epoch 73/100\n",
      "13/13 [==============================] - 5s 410ms/step - loss: 0.4107 - accuracy: 0.9830 - val_loss: 0.7371 - val_accuracy: 0.8441 - lr: 7.8125e-06\n",
      "Epoch 74/100\n",
      "13/13 [==============================] - 6s 438ms/step - loss: 0.4116 - accuracy: 0.9819 - val_loss: 0.7363 - val_accuracy: 0.8438 - lr: 7.8125e-06\n",
      "Epoch 75/100\n",
      "13/13 [==============================] - 5s 401ms/step - loss: 0.4095 - accuracy: 0.9828 - val_loss: 0.7365 - val_accuracy: 0.8441 - lr: 7.8125e-06\n",
      "Epoch 76/100\n",
      "13/13 [==============================] - 6s 433ms/step - loss: 0.4117 - accuracy: 0.9822 - val_loss: 0.7361 - val_accuracy: 0.8450 - lr: 7.8125e-06\n",
      "Epoch 77/100\n",
      "13/13 [==============================] - 6s 433ms/step - loss: 0.4123 - accuracy: 0.9822 - val_loss: 0.7361 - val_accuracy: 0.8431 - lr: 7.8125e-06\n",
      "Epoch 78/100\n",
      "13/13 [==============================] - 5s 398ms/step - loss: 0.4102 - accuracy: 0.9837 - val_loss: 0.7358 - val_accuracy: 0.8444 - lr: 7.8125e-06\n",
      "Epoch 79/100\n",
      "13/13 [==============================] - 5s 392ms/step - loss: 0.4092 - accuracy: 0.9822 - val_loss: 0.7359 - val_accuracy: 0.8428 - lr: 7.8125e-06\n",
      "Epoch 80/100\n",
      "13/13 [==============================] - 5s 409ms/step - loss: 0.4092 - accuracy: 0.9833 - val_loss: 0.7359 - val_accuracy: 0.8431 - lr: 3.9063e-06\n",
      "Epoch 81/100\n",
      "13/13 [==============================] - 6s 461ms/step - loss: 0.4106 - accuracy: 0.9833 - val_loss: 0.7357 - val_accuracy: 0.8444 - lr: 3.9063e-06\n",
      "Epoch 82/100\n",
      "13/13 [==============================] - 6s 432ms/step - loss: 0.4084 - accuracy: 0.9826 - val_loss: 0.7357 - val_accuracy: 0.8428 - lr: 3.9063e-06\n",
      "Epoch 83/100\n",
      "13/13 [==============================] - 6s 469ms/step - loss: 0.4087 - accuracy: 0.9829 - val_loss: 0.7355 - val_accuracy: 0.8434 - lr: 3.9063e-06\n",
      "Epoch 84/100\n",
      "13/13 [==============================] - 5s 426ms/step - loss: 0.4099 - accuracy: 0.9829 - val_loss: 0.7355 - val_accuracy: 0.8434 - lr: 3.9063e-06\n",
      "Epoch 85/100\n",
      "13/13 [==============================] - 5s 408ms/step - loss: 0.4082 - accuracy: 0.9834 - val_loss: 0.7354 - val_accuracy: 0.8428 - lr: 3.9063e-06\n",
      "Epoch 86/100\n",
      "13/13 [==============================] - 5s 364ms/step - loss: 0.4085 - accuracy: 0.9826 - val_loss: 0.7355 - val_accuracy: 0.8438 - lr: 3.9063e-06\n",
      "Epoch 87/100\n",
      "13/13 [==============================] - 6s 507ms/step - loss: 0.4087 - accuracy: 0.9819 - val_loss: 0.7353 - val_accuracy: 0.8434 - lr: 3.9063e-06\n",
      "Epoch 88/100\n",
      "13/13 [==============================] - 5s 375ms/step - loss: 0.4078 - accuracy: 0.9835 - val_loss: 0.7356 - val_accuracy: 0.8434 - lr: 3.9063e-06\n",
      "Epoch 89/100\n",
      "13/13 [==============================] - 5s 406ms/step - loss: 0.4080 - accuracy: 0.9824 - val_loss: 0.7353 - val_accuracy: 0.8434 - lr: 3.9063e-06\n",
      "Epoch 90/100\n",
      "13/13 [==============================] - 5s 380ms/step - loss: 0.4082 - accuracy: 0.9827 - val_loss: 0.7353 - val_accuracy: 0.8428 - lr: 1.9531e-06\n",
      "Epoch 91/100\n",
      "13/13 [==============================] - 5s 366ms/step - loss: 0.4081 - accuracy: 0.9830 - val_loss: 0.7353 - val_accuracy: 0.8425 - lr: 1.9531e-06\n",
      "Epoch 92/100\n",
      "13/13 [==============================] - 5s 415ms/step - loss: 0.4111 - accuracy: 0.9834 - val_loss: 0.7352 - val_accuracy: 0.8431 - lr: 1.9531e-06\n",
      "Epoch 93/100\n",
      "13/13 [==============================] - 4s 302ms/step - loss: 0.4079 - accuracy: 0.9824 - val_loss: 0.7352 - val_accuracy: 0.8425 - lr: 1.9531e-06\n",
      "Epoch 94/100\n",
      "13/13 [==============================] - 5s 409ms/step - loss: 0.4097 - accuracy: 0.9835 - val_loss: 0.7352 - val_accuracy: 0.8431 - lr: 1.9531e-06\n",
      "Epoch 95/100\n",
      "13/13 [==============================] - 4s 336ms/step - loss: 0.4098 - accuracy: 0.9830 - val_loss: 0.7350 - val_accuracy: 0.8441 - lr: 1.9531e-06\n",
      "Epoch 96/100\n",
      "13/13 [==============================] - 5s 359ms/step - loss: 0.4080 - accuracy: 0.9823 - val_loss: 0.7351 - val_accuracy: 0.8431 - lr: 1.9531e-06\n",
      "Epoch 97/100\n",
      "13/13 [==============================] - 5s 377ms/step - loss: 0.4073 - accuracy: 0.9831 - val_loss: 0.7349 - val_accuracy: 0.8431 - lr: 1.9531e-06\n",
      "Epoch 98/100\n",
      "13/13 [==============================] - 5s 373ms/step - loss: 0.4089 - accuracy: 0.9827 - val_loss: 0.7350 - val_accuracy: 0.8428 - lr: 1.9531e-06\n",
      "Epoch 99/100\n",
      "13/13 [==============================] - 5s 349ms/step - loss: 0.4072 - accuracy: 0.9825 - val_loss: 0.7350 - val_accuracy: 0.8434 - lr: 1.9531e-06\n",
      "Epoch 100/100\n",
      "13/13 [==============================] - 5s 391ms/step - loss: 0.4077 - accuracy: 0.9825 - val_loss: 0.7350 - val_accuracy: 0.8431 - lr: 9.7656e-07\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_, y_train_encoded, validation_data=(X_val_, y_val_encoded), epochs=100, batch_size=1024, callbacks=[early_stopping, lr_scheduler])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the training loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss, val_loss = history.history['loss'], history.history['val_loss']\n",
    "\n",
    "plt.plot(loss, label='loss')\n",
    "plt.plot(val_loss, label='val_loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the model on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 1s 14ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.82      0.84       275\n",
      "           1       0.80      0.80      0.80       224\n",
      "           2       0.87      0.92      0.89       695\n",
      "           3       0.70      0.67      0.69       159\n",
      "           4       0.88      0.89      0.89       581\n",
      "           5       0.75      0.55      0.63        66\n",
      "\n",
      "    accuracy                           0.85      2000\n",
      "   macro avg       0.81      0.77      0.79      2000\n",
      "weighted avg       0.85      0.85      0.85      2000\n",
      "\n",
      "[[226   8  12   3  26   0]\n",
      " [  9 179   8   0  20   8]\n",
      " [  6   7 636  35   9   2]\n",
      " [  2   1  40 107   9   0]\n",
      " [ 18  15  21   7 518   2]\n",
      " [  0  13  12   0   5  36]]\n",
      "0.851\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "predictions = model.predict(X_test_)\n",
    "prediction_labels = predictions.argmax(axis=1)\n",
    "print(classification_report(y_test, prediction_labels))\n",
    "print(confusion_matrix(y_test_, prediction_labels))\n",
    "print(accuracy_score(y_test_, prediction_labels))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have tried several dozens of times on this model: increasing and reducing the layers, increasing and reducing the neurons in each layer, tuning the regularization parameter, changing regularization, tuning the learning rate, batch size, *etc*.\n",
    "\n",
    "I also tried to experiment on the different input, using different representation of original text for model training, such as embedding with spacy. There were several different accuracy ceiling for my model from low to high with increasing the model complexity, `34%` to `56%`, and `86%`. And finally I got this result with the tf_idf matrix representation for training the model while the scale of the model is large with nearly 34 million. And the Accuracy on test was improved from `< 40%` to now `> 80%`.\n",
    "\n",
    "With `> 80%` accuracy, I also run dozens of experimentation to improve the accuracy, however, it is very hard to get a better accuracy, in the meantime I am already overfitting with the training set. I tried to tackle the overfitting problem, but I will get lower accuracy. So I decided to keep this model setup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model, the folder of saved model is ignored for commit to github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: FNN_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: FNN_model/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('FNN_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's test on the real case data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load the real case data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   Unnamed: 0                                      article_title  is_ecology\n",
       " 0        1079  Stations essence à Rochefort-en-Terre : les me...           0\n",
       " 1        1515  À Brest, le chantier de La Boussole se fait at...           0\n",
       " 2          51  Météorite en Normandie : à la recherche de pré...           0\n",
       " 3        1419  Résultats trimestriels mitigés pour les géants...           0\n",
       " 4        2181  Opinion | Sobriété énergétique : les solutions...           1,\n",
       "    Unnamed: 0                                      article_title  is_ecology\n",
       " 0          56  Plan de sortie de flotte: seules sept demandes...           0\n",
       " 1         279  Agressé, l’agriculteur Paul François, figure d...           1\n",
       " 2           1  Stations essence à La Bouillie : les meilleurs...           0\n",
       " 3         213  Accord sur le partage de la valeur: le Medef n...           0\n",
       " 4         282  ZFE et et transports en commun : bus et cars d...           1)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_r_train = pd.read_csv('./real_case_data/train.csv')\n",
    "df_r_test = pd.read_csv('./real_case_data/test.csv')\n",
    "\n",
    "df_r_train.head(), df_r_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   Unnamed: 0                                      article_title  is_ecology  \\\n",
       " 0        1079  Stations essence à Rochefort-en-Terre : les me...           0   \n",
       " 1        1515  À Brest, le chantier de La Boussole se fait at...           0   \n",
       " 2          51  Météorite en Normandie : à la recherche de pré...           0   \n",
       " 3        1419  Résultats trimestriels mitigés pour les géants...           0   \n",
       " 4        2181  Opinion | Sobriété énergétique : les solutions...           1   \n",
       " \n",
       "                                            processed  \n",
       " 0  station essence à rochefort - en - terre : les...  \n",
       " 1  à brest , le chantier de la boussole se fait a...  \n",
       " 2  météorite en normandie : à la recherche de pré...  \n",
       " 3  résultats trimestriels mitigés pour les géants...  \n",
       " 4  opinion | sobriété énergétique : les solution ...  ,\n",
       "    Unnamed: 0                                      article_title  is_ecology  \\\n",
       " 0          56  Plan de sortie de flotte: seules sept demandes...           0   \n",
       " 1         279  Agressé, l’agriculteur Paul François, figure d...           1   \n",
       " 2           1  Stations essence à La Bouillie : les meilleurs...           0   \n",
       " 3         213  Accord sur le partage de la valeur: le Medef n...           0   \n",
       " 4         282  ZFE et et transports en commun : bus et cars d...           1   \n",
       " \n",
       "                                            processed  \n",
       " 0  plan de sortie de flotte : seules sept demande...  \n",
       " 1  agressé , l’agriculteur paul françois , figure...  \n",
       " 2  station essence à la bouillie : les meilleurs ...  \n",
       " 3  accord sur le partage de la valeur : le medef ...  \n",
       " 4  zfe et et transport en commun : bus et cars da...  )"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_r_train['processed'] = df_r_train['article_title'].apply(preprocess_text)\n",
    "df_r_test['processed'] = df_r_test['article_title'].apply(preprocess_text)\n",
    "df_r_train.head(), df_r_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TFIDF transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2215, 2446), (294, 2446))"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "final_stopwords_list = stopwords.words('english') + stopwords.words('french')\n",
    "\n",
    "tfidf = TfidfVectorizer(max_df=0.95, min_df=2, stop_words=final_stopwords_list)\n",
    "\n",
    "dtm_r_train = tfidf.fit_transform(df_r_train['processed'])\n",
    "dtm_r_test = tfidf.transform(df_r_test['processed'])\n",
    "dtm_r_train.shape, dtm_r_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the X_r_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_r_train = dtm_r_train.toarray()\n",
    "y_r_train = df_r_train['is_ecology']\n",
    "\n",
    "X_r_test = dtm_r_test.toarray()\n",
    "y_r_test = df_r_test['is_ecology']\n",
    "\n",
    "y_r_train_encoded = to_categorical(y_r_train)\n",
    "y_r_test_encoded = to_categorical(y_r_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the train and validation data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# class_weights = compute_class_weight('balanced', classes=np.unique(y_r_train), y=y_r_train)\n",
    "X_r_train, X_r_val, y_r_train_encoded, y_r_val_encoded = train_test_split(X_r_train, y_r_train_encoded, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1772, 2446), (443, 2446), (1772, 2), (443, 2))"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_r_train.shape, X_r_val.shape, y_r_train_encoded.shape, y_r_val_encoded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the model with same architecture, but change the last output layer as we have two categories in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_91 (Dense)            (None, 2048)              5011456   \n",
      "                                                                 \n",
      " dense_92 (Dense)            (None, 1024)              2098176   \n",
      "                                                                 \n",
      " dense_93 (Dense)            (None, 512)               524800    \n",
      "                                                                 \n",
      " dropout_25 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_94 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_95 (Dense)            (None, 64)                16448     \n",
      "                                                                 \n",
      " dense_96 (Dense)            (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7782338 (29.69 MB)\n",
      "Trainable params: 7782338 (29.69 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras import Sequential\n",
    "import tensorflow as tf\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(2048, activation='selu', kernel_initializer='lecun_normal', input_shape=(X_r_train.shape[1],), kernel_regularizer=tf.keras.regularizers.l2(0.01)))\n",
    "model.add(Dense(1024, activation='selu', kernel_initializer='lecun_normal', kernel_regularizer=tf.keras.regularizers.l2(0.01)))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(512, activation='selu', kernel_initializer='lecun_normal', kernel_regularizer=tf.keras.regularizers.l2(0.1)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(256, activation='selu', kernel_initializer='lecun_normal', ))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(128, activation='selu', kernel_initializer='lecun_normal', ))\n",
    "model.add(Dense(64, activation='selu', kernel_initializer='lecun_normal',))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='Adam', loss=tf.losses.categorical_crossentropy, metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up early stopping and dynamic learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.callbacks import EarlyStopping, CallbackList, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "def step_decay(epoch):\n",
    "    initial_lrate = 0.001\n",
    "    drop = 0.5\n",
    "    epochs_drop = 10.0\n",
    "    lrate = initial_lrate * math.pow(drop, math.floor((1 + epoch) / epochs_drop))\n",
    "    return lrate\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(step_decay)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', restore_best_weights=True, patience=5) # "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 577ms/step - loss: 80.4360 - accuracy: 0.6569 - val_loss: 72.9263 - val_accuracy: 0.9887 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 71.1564 - accuracy: 0.9735 - val_loss: 64.3972 - val_accuracy: 0.9887 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 155ms/step - loss: 62.7544 - accuracy: 0.9735 - val_loss: 56.6188 - val_accuracy: 0.9887 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 55.1133 - accuracy: 0.9746 - val_loss: 49.6199 - val_accuracy: 0.9887 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 48.2469 - accuracy: 0.9825 - val_loss: 43.3426 - val_accuracy: 0.9887 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 165ms/step - loss: 42.1144 - accuracy: 0.9876 - val_loss: 37.7838 - val_accuracy: 0.9887 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 157ms/step - loss: 36.6825 - accuracy: 0.9921 - val_loss: 32.8671 - val_accuracy: 0.9887 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 272ms/step - loss: 31.8843 - accuracy: 0.9989 - val_loss: 28.5340 - val_accuracy: 0.9887 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 154ms/step - loss: 27.6654 - accuracy: 1.0000 - val_loss: 24.7314 - val_accuracy: 0.9887 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 24.3249 - accuracy: 1.0000 - val_loss: 23.0195 - val_accuracy: 0.9887 - lr: 5.0000e-04\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 172ms/step - loss: 22.6391 - accuracy: 1.0000 - val_loss: 21.4287 - val_accuracy: 0.9887 - lr: 5.0000e-04\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 140ms/step - loss: 21.0720 - accuracy: 1.0000 - val_loss: 19.9478 - val_accuracy: 0.9887 - lr: 5.0000e-04\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 19.6130 - accuracy: 1.0000 - val_loss: 18.5679 - val_accuracy: 0.9887 - lr: 5.0000e-04\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 138ms/step - loss: 18.2539 - accuracy: 1.0000 - val_loss: 17.2813 - val_accuracy: 0.9887 - lr: 5.0000e-04\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 140ms/step - loss: 16.9872 - accuracy: 1.0000 - val_loss: 16.0827 - val_accuracy: 0.9887 - lr: 5.0000e-04\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 15.8069 - accuracy: 1.0000 - val_loss: 14.9672 - val_accuracy: 0.9887 - lr: 5.0000e-04\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 14.7082 - accuracy: 1.0000 - val_loss: 13.9289 - val_accuracy: 0.9887 - lr: 5.0000e-04\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 13.6846 - accuracy: 1.0000 - val_loss: 12.9630 - val_accuracy: 0.9887 - lr: 5.0000e-04\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 12.7313 - accuracy: 1.0000 - val_loss: 12.0640 - val_accuracy: 0.9887 - lr: 5.0000e-04\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 11.9335 - accuracy: 1.0000 - val_loss: 11.6396 - val_accuracy: 0.9887 - lr: 2.5000e-04\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 11.5128 - accuracy: 1.0000 - val_loss: 11.2331 - val_accuracy: 0.9887 - lr: 2.5000e-04\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 11.1096 - accuracy: 1.0000 - val_loss: 10.8428 - val_accuracy: 0.9887 - lr: 2.5000e-04\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 10.7227 - accuracy: 1.0000 - val_loss: 10.4677 - val_accuracy: 0.9887 - lr: 2.5000e-04\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 160ms/step - loss: 10.3506 - accuracy: 1.0000 - val_loss: 10.1070 - val_accuracy: 0.9887 - lr: 2.5000e-04\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 9.9921 - accuracy: 1.0000 - val_loss: 9.7595 - val_accuracy: 0.9887 - lr: 2.5000e-04\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 9.6464 - accuracy: 1.0000 - val_loss: 9.4243 - val_accuracy: 0.9887 - lr: 2.5000e-04\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 9.3130 - accuracy: 1.0000 - val_loss: 9.1003 - val_accuracy: 0.9887 - lr: 2.5000e-04\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 8.9912 - accuracy: 1.0000 - val_loss: 8.7868 - val_accuracy: 0.9887 - lr: 2.5000e-04\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 8.6802 - accuracy: 1.0000 - val_loss: 8.4840 - val_accuracy: 0.9887 - lr: 2.5000e-04\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 8.4106 - accuracy: 1.0000 - val_loss: 8.3369 - val_accuracy: 0.9887 - lr: 1.2500e-04\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 8.2642 - accuracy: 1.0000 - val_loss: 8.1931 - val_accuracy: 0.9887 - lr: 1.2500e-04\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 270ms/step - loss: 8.1206 - accuracy: 1.0000 - val_loss: 8.0523 - val_accuracy: 0.9887 - lr: 1.2500e-04\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 7.9797 - accuracy: 1.0000 - val_loss: 7.9142 - val_accuracy: 0.9887 - lr: 1.2500e-04\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 7.8413 - accuracy: 1.0000 - val_loss: 7.7781 - val_accuracy: 0.9887 - lr: 1.2500e-04\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 7.7056 - accuracy: 1.0000 - val_loss: 7.6439 - val_accuracy: 0.9887 - lr: 1.2500e-04\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 7.5716 - accuracy: 1.0000 - val_loss: 7.5115 - val_accuracy: 0.9887 - lr: 1.2500e-04\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 7.4400 - accuracy: 1.0000 - val_loss: 7.3810 - val_accuracy: 0.9887 - lr: 1.2500e-04\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 7.3102 - accuracy: 1.0000 - val_loss: 7.2526 - val_accuracy: 0.9887 - lr: 1.2500e-04\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 7.1825 - accuracy: 1.0000 - val_loss: 7.1263 - val_accuracy: 0.9887 - lr: 1.2500e-04\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 230ms/step - loss: 7.0697 - accuracy: 1.0000 - val_loss: 7.0640 - val_accuracy: 0.9887 - lr: 6.2500e-05\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 177ms/step - loss: 7.0071 - accuracy: 1.0000 - val_loss: 7.0024 - val_accuracy: 0.9887 - lr: 6.2500e-05\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 123ms/step - loss: 6.9453 - accuracy: 1.0000 - val_loss: 6.9411 - val_accuracy: 0.9887 - lr: 6.2500e-05\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 6.8839 - accuracy: 1.0000 - val_loss: 6.8802 - val_accuracy: 0.9887 - lr: 6.2500e-05\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 6.8228 - accuracy: 1.0000 - val_loss: 6.8196 - val_accuracy: 0.9887 - lr: 6.2500e-05\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 166ms/step - loss: 6.7625 - accuracy: 1.0000 - val_loss: 6.7592 - val_accuracy: 0.9887 - lr: 6.2500e-05\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 6.7021 - accuracy: 1.0000 - val_loss: 6.6991 - val_accuracy: 0.9887 - lr: 6.2500e-05\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 6.6421 - accuracy: 1.0000 - val_loss: 6.6393 - val_accuracy: 0.9887 - lr: 6.2500e-05\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 256ms/step - loss: 6.5827 - accuracy: 1.0000 - val_loss: 6.5799 - val_accuracy: 0.9887 - lr: 6.2500e-05\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 169ms/step - loss: 6.5233 - accuracy: 1.0000 - val_loss: 6.5208 - val_accuracy: 0.9887 - lr: 6.2500e-05\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 6.4706 - accuracy: 1.0000 - val_loss: 6.4915 - val_accuracy: 0.9887 - lr: 3.1250e-05\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 6.4412 - accuracy: 1.0000 - val_loss: 6.4623 - val_accuracy: 0.9887 - lr: 3.1250e-05\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 6.4118 - accuracy: 1.0000 - val_loss: 6.4332 - val_accuracy: 0.9887 - lr: 3.1250e-05\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 6.3826 - accuracy: 1.0000 - val_loss: 6.4041 - val_accuracy: 0.9887 - lr: 3.1250e-05\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 6.3534 - accuracy: 1.0000 - val_loss: 6.3749 - val_accuracy: 0.9887 - lr: 3.1250e-05\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 6.3240 - accuracy: 1.0000 - val_loss: 6.3458 - val_accuracy: 0.9887 - lr: 3.1250e-05\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 237ms/step - loss: 6.2949 - accuracy: 1.0000 - val_loss: 6.3168 - val_accuracy: 0.9887 - lr: 3.1250e-05\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 6.2657 - accuracy: 1.0000 - val_loss: 6.2877 - val_accuracy: 0.9887 - lr: 3.1250e-05\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 6.2367 - accuracy: 1.0000 - val_loss: 6.2586 - val_accuracy: 0.9887 - lr: 3.1250e-05\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 222ms/step - loss: 6.2075 - accuracy: 1.0000 - val_loss: 6.2295 - val_accuracy: 0.9887 - lr: 3.1250e-05\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 6.1815 - accuracy: 1.0000 - val_loss: 6.2150 - val_accuracy: 0.9887 - lr: 1.5625e-05\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 6.1669 - accuracy: 1.0000 - val_loss: 6.2004 - val_accuracy: 0.9887 - lr: 1.5625e-05\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 6.1525 - accuracy: 1.0000 - val_loss: 6.1859 - val_accuracy: 0.9887 - lr: 1.5625e-05\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 6.1380 - accuracy: 1.0000 - val_loss: 6.1713 - val_accuracy: 0.9887 - lr: 1.5625e-05\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 215ms/step - loss: 6.1234 - accuracy: 1.0000 - val_loss: 6.1567 - val_accuracy: 0.9887 - lr: 1.5625e-05\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 6.1087 - accuracy: 1.0000 - val_loss: 6.1422 - val_accuracy: 0.9887 - lr: 1.5625e-05\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 6.0943 - accuracy: 1.0000 - val_loss: 6.1276 - val_accuracy: 0.9887 - lr: 1.5625e-05\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 6.0796 - accuracy: 1.0000 - val_loss: 6.1129 - val_accuracy: 0.9887 - lr: 1.5625e-05\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 6.0650 - accuracy: 1.0000 - val_loss: 6.0983 - val_accuracy: 0.9887 - lr: 1.5625e-05\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 6.0502 - accuracy: 1.0000 - val_loss: 6.0836 - val_accuracy: 0.9887 - lr: 1.5625e-05\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 6.0372 - accuracy: 1.0000 - val_loss: 6.0763 - val_accuracy: 0.9887 - lr: 7.8125e-06\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 141ms/step - loss: 6.0299 - accuracy: 1.0000 - val_loss: 6.0689 - val_accuracy: 0.9887 - lr: 7.8125e-06\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 6.0225 - accuracy: 1.0000 - val_loss: 6.0616 - val_accuracy: 0.9887 - lr: 7.8125e-06\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 6.0151 - accuracy: 1.0000 - val_loss: 6.0542 - val_accuracy: 0.9887 - lr: 7.8125e-06\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 138ms/step - loss: 6.0078 - accuracy: 1.0000 - val_loss: 6.0468 - val_accuracy: 0.9887 - lr: 7.8125e-06\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 6.0004 - accuracy: 1.0000 - val_loss: 6.0394 - val_accuracy: 0.9887 - lr: 7.8125e-06\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 124ms/step - loss: 5.9929 - accuracy: 1.0000 - val_loss: 6.0319 - val_accuracy: 0.9887 - lr: 7.8125e-06\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 5.9854 - accuracy: 1.0000 - val_loss: 6.0245 - val_accuracy: 0.9887 - lr: 7.8125e-06\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 124ms/step - loss: 5.9783 - accuracy: 1.0000 - val_loss: 6.0171 - val_accuracy: 0.9887 - lr: 7.8125e-06\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 5.9706 - accuracy: 1.0000 - val_loss: 6.0096 - val_accuracy: 0.9887 - lr: 7.8125e-06\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 5.9639 - accuracy: 1.0000 - val_loss: 6.0059 - val_accuracy: 0.9887 - lr: 3.9063e-06\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 222ms/step - loss: 5.9602 - accuracy: 1.0000 - val_loss: 6.0021 - val_accuracy: 0.9887 - lr: 3.9063e-06\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 140ms/step - loss: 5.9565 - accuracy: 1.0000 - val_loss: 5.9984 - val_accuracy: 0.9887 - lr: 3.9063e-06\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 5.9528 - accuracy: 1.0000 - val_loss: 5.9946 - val_accuracy: 0.9887 - lr: 3.9063e-06\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 5.9488 - accuracy: 1.0000 - val_loss: 5.9908 - val_accuracy: 0.9887 - lr: 3.9063e-06\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 123ms/step - loss: 5.9451 - accuracy: 1.0000 - val_loss: 5.9870 - val_accuracy: 0.9887 - lr: 3.9063e-06\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 181ms/step - loss: 5.9413 - accuracy: 1.0000 - val_loss: 5.9833 - val_accuracy: 0.9887 - lr: 3.9063e-06\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 123ms/step - loss: 5.9377 - accuracy: 1.0000 - val_loss: 5.9795 - val_accuracy: 0.9887 - lr: 3.9063e-06\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 160ms/step - loss: 5.9336 - accuracy: 1.0000 - val_loss: 5.9756 - val_accuracy: 0.9887 - lr: 3.9063e-06\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 347ms/step - loss: 5.9298 - accuracy: 1.0000 - val_loss: 5.9718 - val_accuracy: 0.9887 - lr: 3.9063e-06\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 5.9264 - accuracy: 1.0000 - val_loss: 5.9699 - val_accuracy: 0.9887 - lr: 1.9531e-06\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 5.9247 - accuracy: 1.0000 - val_loss: 5.9680 - val_accuracy: 0.9887 - lr: 1.9531e-06\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 5.9227 - accuracy: 1.0000 - val_loss: 5.9661 - val_accuracy: 0.9887 - lr: 1.9531e-06\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 5.9208 - accuracy: 1.0000 - val_loss: 6.0330 - val_accuracy: 0.9887 - lr: 1.9531e-06\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 5.9188 - accuracy: 1.0000 - val_loss: 5.9622 - val_accuracy: 0.9887 - lr: 1.9531e-06\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 5.9171 - accuracy: 1.0000 - val_loss: 5.9603 - val_accuracy: 0.9887 - lr: 1.9531e-06\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 5.9150 - accuracy: 1.0000 - val_loss: 5.9584 - val_accuracy: 0.9887 - lr: 1.9531e-06\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 229ms/step - loss: 5.9129 - accuracy: 1.0000 - val_loss: 5.9564 - val_accuracy: 0.9887 - lr: 1.9531e-06\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 5.9110 - accuracy: 1.0000 - val_loss: 5.9545 - val_accuracy: 0.9887 - lr: 1.9531e-06\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 5.9091 - accuracy: 1.0000 - val_loss: 5.9525 - val_accuracy: 0.9887 - lr: 1.9531e-06\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 123ms/step - loss: 5.9072 - accuracy: 1.0000 - val_loss: 5.9515 - val_accuracy: 0.9887 - lr: 9.7656e-07\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_r_train, y_r_train_encoded, validation_data=(X_r_val, y_r_val_encoded), epochs=100, batch_size=1024, callbacks=[early_stopping, lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 14ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91       241\n",
      "           1       1.00      0.08      0.14        53\n",
      "\n",
      "    accuracy                           0.83       294\n",
      "   macro avg       0.92      0.54      0.52       294\n",
      "weighted avg       0.86      0.83      0.77       294\n",
      "\n",
      "[[241   0]\n",
      " [ 49   4]]\n",
      "0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "predictions_r = model.predict(X_r_test)\n",
    "prediction_labels_r = predictions_r.argmax(axis=1)\n",
    "print(classification_report(y_r_test, prediction_labels_r))\n",
    "print(confusion_matrix(y_r_test, prediction_labels_r))\n",
    "print(accuracy_score(y_r_test, prediction_labels_r))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN, LSTM and GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 1000, 100)         1518600   \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 1024)              4608000   \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 512)               524800    \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 6)                 390       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,824,270\n",
      "Trainable params: 6,824,270\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "import math\n",
    "import tensorflow as tf\n",
    "\n",
    "# 数据处理\n",
    "tweets_train = df_train['tweet']\n",
    "tweet_test = df_test['tweet']\n",
    "labels_train = df_train['sentiment']\n",
    "labels_test = df_test['sentiment']\n",
    "\n",
    "verctorizer = TfidfVectorizer()\n",
    "X_train_tfidf = verctorizer.fit_transform(tweets_train)\n",
    "X_test_tfidf = verctorizer.transform(tweet_test)\n",
    "\n",
    "max_sequence_length = 1000\n",
    "X_train_padded = pad_sequences(X_train_tfidf.toarray(), maxlen=max_sequence_length)\n",
    "X_test_padded = pad_sequences(X_test_tfidf.toarray(), maxlen=max_sequence_length)\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train_padded = le.fit_transform(labels_train)\n",
    "y_test_padded = le.transform(labels_test)\n",
    "\n",
    "# Convert labels to categorical if needed\n",
    "# y_train_padded = to_categorical(y_train_padded)\n",
    "# y_test_padded = to_categorical(y_test_padded)\n",
    "\n",
    "num_classes = len(le.classes_)\n",
    "vocab_size = len(verctorizer.vocabulary_)\n",
    "embedding_dim = 100\n",
    "\n",
    "# 设置学习率与early_stopping\n",
    "def step_decay(epoch):\n",
    "    initial_lrate = 0.01\n",
    "    drop = 0.5\n",
    "    epochs_drop = 10.0\n",
    "    lrate = initial_lrate * math.pow(drop, math.floor((1 + epoch) / epochs_drop))\n",
    "    return lrate\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(step_decay)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', restore_best_weights=True, patience=5)\n",
    "\n",
    "# strategy = tf.distribute.OneDeviceStrategy(device='/gpu:0')\n",
    "# 搭建模型\n",
    "# with strategy.scope():\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim, input_length=max_sequence_length))\n",
    "model.add(LSTM(1024, recurrent_dropout=0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练模型\n",
    "history = model.fit(X_train_padded, y_train_padded, batch_size=512, epochs=100,\n",
    "                    validation_data=(X_test_padded, y_test_padded),\n",
    "                    callbacks=[early_stopping, lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, val_loos = history['loss'], history['val_loss']\n",
    "\n",
    "plt.plot(loss, label='Training loss')\n",
    "plt.plot(val_loos, label='Validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer based Pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet sentiment\n",
       "0                            i didnt feel humiliated   sadness\n",
       "1  i can go from feeling so hopeless to so damned...   sadness\n",
       "2   im grabbing a minute to post i feel greedy wrong     anger\n",
       "3  i am ever feeling nostalgic about the fireplac...      love\n",
       "4                               i am feeling grouchy     anger"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('./train.txt', header=None, delimiter=';')\n",
    "df_test = pd.read_csv('./test.txt', header=None, delimiter=';')\n",
    "df_train = df_train.rename(columns={0: 'tweet', 1: 'sentiment'})\n",
    "df_test = df_test.rename(columns={0: 'tweet', 1: 'sentiment'})\n",
    "df_train.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, BertTokenizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "encoded_input_train = tokenizer.batch_encode_plus(texts_train, padding=True, truncation=True, return_tensors='pt')\n",
    "input_ids_train = encoded_input_train['input_ids']\n",
    "attention_masks_train = encoded_input_train['attention_mask']\n",
    "\n",
    "labels_train = df_train['sentiment']\n",
    "le = LabelEncoder()\n",
    "labels_train =le.fit_transform(labels_train)\n",
    "labels_train = to_categorical(labels_train)\n",
    "labels_train = torch.tensor(labels_train)\n",
    "\n",
    "\n",
    "transformer_model = AutoModel.from_pretrained('bert-base-uncased')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "transformer_model.to(device)\n",
    "optimizer = torch.optim.Adam(transformer_model.parameters(), lr=1e-5)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "transformer_model.train()\n",
    "input_ids_train = input_ids_train.to(device)\n",
    "attention_masks_train = attention_masks_train.to(device)\n",
    "labels_train = labels_train.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0020, -0.0545, -0.0427,  ..., -0.0806, -0.0876,  0.0259],\n",
       "        [-0.0798, -0.0748,  0.0032,  ...,  0.0238,  0.0873, -0.0114],\n",
       "        [-0.0061, -0.0134,  0.0178,  ...,  0.0522,  0.0160, -0.0167],\n",
       "        [ 0.0459, -0.0031,  0.0880,  ...,  0.0709, -0.0803,  0.0415],\n",
       "        [ 0.0195, -0.0304, -0.0010,  ...,  0.0190, -0.0422,  0.0654],\n",
       "        [ 0.0330,  0.0297, -0.0718,  ...,  0.0068,  0.0588, -0.0725]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "transformer_model = AutoModel.from_pretrained('bert-base-uncased')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "transformer_model.to(device)\n",
    "optimizer = torch.optim.Adam(transformer_model.parameters(), lr=1e-5)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "texts_train = df_train['tweet']\n",
    "labels_train = df_train['sentiment']\n",
    "le = LabelEncoder()\n",
    "labels_train = le.fit_transform(labels_train)\n",
    "labels_train = to_categorical(labels_train)\n",
    "labels_train = torch.tensor(labels_train).to(device)\n",
    "\n",
    "# Tokenize texts_train\n",
    "encoded_inputs = tokenizer(texts_train.tolist(), padding=True, truncation=True, return_tensors='pt')\n",
    "input_ids_train = encoded_inputs['input_ids'].to(device)\n",
    "attention_masks_train = encoded_inputs['attention_mask'].to(device)\n",
    "\n",
    "train_dataset = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "transformer_model.train()\n",
    "\n",
    "linear_layer = nn.Linear(transformer_model.config.hidden_size, le.classes_.shape[0]).to(device)\n",
    "nn.init.xavier_uniform_(linear_layer.weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Average Loss: 0.3431227789670229\n",
      "Epoch 2 - Average Loss: 0.15944166499562562\n",
      "Epoch 3 - Average Loss: 0.07959097695350648\n",
      "Epoch 4 - Average Loss: 0.05580993509478867\n",
      "Epoch 5 - Average Loss: 0.04338084980705753\n",
      "Epoch 6 - Average Loss: 0.03838919259759132\n",
      "Epoch 7 - Average Loss: 0.03426969006942818\n",
      "Epoch 8 - Average Loss: 0.030790360981074627\n",
      "Epoch 9 - Average Loss: 0.027876388156437316\n",
      "Epoch 10 - Average Loss: 0.02630211615844746\n",
      "Epoch 11 - Average Loss: 0.02624506679715705\n",
      "Epoch 12 - Average Loss: 0.025121578735153888\n",
      "Epoch 13 - Average Loss: 0.023111631666950416\n",
      "Epoch 14 - Average Loss: 0.0223442898268695\n",
      "Epoch 15 - Average Loss: 0.02088869621325284\n",
      "Epoch 16 - Average Loss: 0.02109514506465348\n",
      "Epoch 17 - Average Loss: 0.018455659539700717\n",
      "Epoch 18 - Average Loss: 0.017144603587701566\n",
      "Epoch 19 - Average Loss: 0.017530029333669518\n",
      "Epoch 20 - Average Loss: 0.017526032913141535\n",
      "Epoch 21 - Average Loss: 0.016154191977955635\n",
      "Epoch 22 - Average Loss: 0.015543671893923602\n",
      "Epoch 23 - Average Loss: 0.014400973078576499\n",
      "Epoch 24 - Average Loss: 0.015483351661096094\n",
      "Epoch 25 - Average Loss: 0.01510167918575462\n",
      "Epoch 26 - Average Loss: 0.014666177272785717\n",
      "Epoch 27 - Average Loss: 0.013452183268545923\n",
      "Epoch 28 - Average Loss: 0.014083862124072767\n",
      "Epoch 29 - Average Loss: 0.011417762398523337\n",
      "Epoch 30 - Average Loss: 0.011542539221383777\n"
     ]
    }
   ],
   "source": [
    "accumulation_steps = 4  # Accumulate gradients over 4 batches\n",
    "total_losses = []\n",
    "for epoch in range(30):\n",
    "    total_loss = 0\n",
    "    for batch_idx, (batch_input_ids, batch_attention_masks, batch_labels) in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        batch_input_ids = batch_input_ids.to(device)\n",
    "        batch_attention_masks = batch_attention_masks.to(device)\n",
    "        batch_labels = batch_labels.to(device)\n",
    "\n",
    "        outputs = transformer_model(input_ids=batch_input_ids, attention_mask=batch_attention_masks)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        logits = linear_layer(pooled_output)\n",
    "\n",
    "        loss = loss_fn(logits, torch.argmax(batch_labels, dim=1))\n",
    "        loss = loss / accumulation_steps  # Scale the loss\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        if (batch_idx + 1) % accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    total_losses.append(total_loss / len(train_dataloader))\n",
    "    print(f\"Epoch {epoch + 1} - Average Loss: {total_loss / len(train_dataloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Tokenize the input test text and convert it to input tensors\n",
    "texts_test = df_test['tweet']\n",
    "labels_test = df_test['sentiment']\n",
    "le = LabelEncoder()\n",
    "labels_test = le.fit_transform(labels_test)\n",
    "labels_test = to_categorical(labels_test)\n",
    "labels_test = torch.tensor(labels_test).to(device)\n",
    "\n",
    "# Tokenize texts_test\n",
    "encoded_inputs = tokenizer(texts_test.tolist(), padding=True, truncation=True, return_tensors='pt')\n",
    "input_ids = encoded_inputs['input_ids'].to(device)\n",
    "attention_masks = encoded_inputs['attention_mask'].to(device)\n",
    "\n",
    "# Inference\n",
    "with torch.no_grad():\n",
    "    outputs = transformer_model(input_ids, attention_masks)\n",
    "    last_hidden_states = outputs.last_hidden_state\n",
    "    logits = linear_layer(last_hidden_states[:, 0, :])\n",
    "    probabilities = torch.softmax(logits, dim=1)\n",
    "    _, predicted_classes = torch.max(probabilities, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.0800\n",
      "Test F1-Score: 0.0870\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.01      0.00      0.00       275\n",
      "           1       0.02      0.06      0.03       224\n",
      "           2       0.64      0.08      0.15       695\n",
      "           3       0.23      0.50      0.32       159\n",
      "           4       0.11      0.01      0.02       581\n",
      "           5       0.00      0.02      0.00        66\n",
      "\n",
      "    accuracy                           0.08      2000\n",
      "   macro avg       0.17      0.11      0.09      2000\n",
      "weighted avg       0.28      0.08      0.09      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted_classes = predicted_classes.cpu().numpy()\n",
    "labels_test = torch.argmax(labels_test, dim=1).cpu().numpy()\n",
    "\n",
    "accuracy = accuracy_score(labels_test, predicted_classes)\n",
    "f1 = f1_score(labels_test, predicted_classes, average='weighted')\n",
    "classification_reports = classification_report(labels_test, predicted_classes)\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Test F1-Score: {f1:.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./models/Bert/BertBasedModelTokenizer\\\\tokenizer_config.json',\n",
       " './models/Bert/BertBasedModelTokenizer\\\\special_tokens_map.json',\n",
       " './models/Bert/BertBasedModelTokenizer\\\\vocab.txt',\n",
       " './models/Bert/BertBasedModelTokenizer\\\\added_tokens.json',\n",
       " './models/Bert/BertBasedModelTokenizer\\\\tokenizer.json')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Persistance a transfer learning pretrained model in PyTorch\n",
    "# Save the model state dict\n",
    "torch.save(transformer_model.state_dict(), './models/Bert/BertBasedModel.pth')\n",
    "# Save the tokenizer\n",
    "tokenizer.save_pretrained('./models/Bert/BertBasedModelTokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load transfer learning pretrained model in PyTorch\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "model =AutoModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Load the model weights\n",
    "model.load_state_dict(torch.load('./models/BertBasedModel.pth'))\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('./models/BertBasedModelTokenizer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define my transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "class TransformerClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_classes, num_layers, num_heads, dropout):\n",
    "        super(TransformerClassifier, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(embedding_dim, num_heads, dim_feedforward=hidden_dim, dropout=dropout),\n",
    "            num_layers=num_layers\n",
    "        )\n",
    "        self.fc = nn.Linear(embedding_dim, num_classes)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        embedded = self.embedding(input_ids)\n",
    "        encoded = self.transformer_encoder(embedded.transpose(0, 1), src_key_padding_mask=attention_mask)\n",
    "        pooled = encoded.mean(dim=0)\n",
    "        logits = self.fc(pooled)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "only bool and floating types of src_key_padding_mask are supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 40\u001b[0m\n\u001b[0;32m     37\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m     39\u001b[0m \u001b[39m# Forward pass\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m logits \u001b[39m=\u001b[39m model(batch_input_ids, batch_attention_masks)\n\u001b[0;32m     41\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(logits, torch\u001b[39m.\u001b[39margmax(batch_labels, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[0;32m     43\u001b[0m \u001b[39m# Backward pass and optimization\u001b[39;00m\n",
      "File \u001b[1;32me:\\Anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[24], line 19\u001b[0m, in \u001b[0;36mTransformerClassifier.forward\u001b[1;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, input_ids, attention_mask):\n\u001b[0;32m     18\u001b[0m     embedded \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding(input_ids)\n\u001b[1;32m---> 19\u001b[0m     encoded \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransformer_encoder(embedded\u001b[39m.\u001b[39;49mtranspose(\u001b[39m0\u001b[39;49m, \u001b[39m1\u001b[39;49m), src_key_padding_mask\u001b[39m=\u001b[39;49mattention_mask)\n\u001b[0;32m     20\u001b[0m     pooled \u001b[39m=\u001b[39m encoded\u001b[39m.\u001b[39mmean(dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m     21\u001b[0m     logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc(pooled)\n",
      "File \u001b[1;32me:\\Anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32me:\\Anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:214\u001b[0m, in \u001b[0;36mTransformerEncoder.forward\u001b[1;34m(self, src, mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[0;32m    196\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[0;32m    197\u001b[0m         src: Tensor,\n\u001b[0;32m    198\u001b[0m         mask: Optional[Tensor] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    199\u001b[0m         src_key_padding_mask: Optional[Tensor] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    200\u001b[0m         is_causal: Optional[\u001b[39mbool\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m    201\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Pass the input through the encoder layers in turn.\u001b[39;00m\n\u001b[0;32m    202\u001b[0m \n\u001b[0;32m    203\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[39m        see the docs in Transformer class.\u001b[39;00m\n\u001b[0;32m    213\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 214\u001b[0m     src_key_padding_mask \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39;49m_canonical_mask(\n\u001b[0;32m    215\u001b[0m         mask\u001b[39m=\u001b[39;49msrc_key_padding_mask,\n\u001b[0;32m    216\u001b[0m         mask_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39msrc_key_padding_mask\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    217\u001b[0m         other_type\u001b[39m=\u001b[39;49mF\u001b[39m.\u001b[39;49m_none_or_dtype(mask),\n\u001b[0;32m    218\u001b[0m         other_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mmask\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    219\u001b[0m         target_type\u001b[39m=\u001b[39;49msrc\u001b[39m.\u001b[39;49mdtype\n\u001b[0;32m    220\u001b[0m     )\n\u001b[0;32m    222\u001b[0m     mask \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39m_canonical_mask(\n\u001b[0;32m    223\u001b[0m         mask\u001b[39m=\u001b[39mmask,\n\u001b[0;32m    224\u001b[0m         mask_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmask\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    228\u001b[0m         check_other\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    229\u001b[0m     )\n\u001b[0;32m    231\u001b[0m     output \u001b[39m=\u001b[39m src\n",
      "File \u001b[1;32me:\\Anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\functional.py:4995\u001b[0m, in \u001b[0;36m_canonical_mask\u001b[1;34m(mask, mask_name, other_type, other_name, target_type, check_other)\u001b[0m\n\u001b[0;32m   4993\u001b[0m _mask_is_float \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mis_floating_point(mask)\n\u001b[0;32m   4994\u001b[0m \u001b[39mif\u001b[39;00m _mask_dtype \u001b[39m!=\u001b[39m torch\u001b[39m.\u001b[39mbool \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m _mask_is_float:\n\u001b[1;32m-> 4995\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\n\u001b[0;32m   4996\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39monly bool and floating types of \u001b[39m\u001b[39m{\u001b[39;00mmask_name\u001b[39m}\u001b[39;00m\u001b[39m are supported\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   4997\u001b[0m \u001b[39mif\u001b[39;00m check_other \u001b[39mand\u001b[39;00m other_type \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   4998\u001b[0m     \u001b[39mif\u001b[39;00m _mask_dtype \u001b[39m!=\u001b[39m other_type:\n",
      "\u001b[1;31mAssertionError\u001b[0m: only bool and floating types of src_key_padding_mask are supported"
     ]
    }
   ],
   "source": [
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Define hyperparameters\n",
    "vocab_size = len(tokenizer)\n",
    "embedding_dim = 128\n",
    "hidden_dim = 256\n",
    "num_classes = 6\n",
    "num_layers = 2\n",
    "num_heads = 4\n",
    "dropout = 0.2\n",
    "learning_rate = 1e-3\n",
    "batch_size = 16\n",
    "num_epochs = 30\n",
    "\n",
    "model = TransformerClassifier(vocab_size, embedding_dim, hidden_dim, num_classes, num_layers, num_heads, dropout)\n",
    "model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Create DataLoader\n",
    "train_dataset = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for batch_input_ids, batch_attention_masks, batch_labels in train_dataloader:\n",
    "        # Move batch tensors to device\n",
    "        batch_input_ids = batch_input_ids.to(device)\n",
    "        batch_attention_masks = batch_attention_masks.to(device)\n",
    "        batch_labels = batch_labels.to(device)\n",
    "        \n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        logits = model(batch_input_ids, batch_attention_masks)\n",
    "        loss = loss_fn(logits, torch.argmax(batch_labels, dim=1))\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    average_loss = total_loss / len(train_dataloader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {average_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model persistance\n",
    "\n",
    "torch.save(model.state_dict(), './models/MyTransformer.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "\n",
    "model_new = TransformerClassifier(vocab_size, \n",
    "                                  embedding_dim, \n",
    "                                  hidden_dim, \n",
    "                                  num_classes, \n",
    "                                  num_layers, \n",
    "                                  num_heads, \n",
    "                                  dropout)\n",
    "\n",
    "model.load_state_dict(torch.load('/models/BertBasedModel.pth'))\n",
    "model.to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load models:\n",
    "`my_model = tf.keras.models.load_model('my_model')`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.decomposition import LatentDirichletAllocation, NMF\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components=32, max_iter=5, learning_method='online', learning_offset=50.,random_state=0)\n",
    "lda.fit(dtm_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
